---
title: "第八章、马尔可夫链蒙特卡罗"
author: "李洁"
date: "2022/3/20"
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
output: 
      html_document : 
        toc: yes
        toc_float: yes
        toc.depth: 6
        toc_depth: 6
        theme: paper
        df_print: tibble
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = " ",
	prompt = TRUE,
	results = "hold"
)
```

概率总是一个不那么让人喜欢的东西。在神话中，只有亡命之徒采取乞求幸运女神，而大多数人只相信智慧女神。当然，对科学而言，其应该是智慧女神的领地，幸运女神在科学领域毫无作用。

但是直到20世纪，两个完全对立的女神开始了合作。作为智慧女神的拥护者，科学家们开始写关于随机数的书，开始使用随机的观点来研究客观世界。直到现在，智慧和运气变成了完全合作的关系。没有人在质疑随机在科学研究中的作用。从天气预报、到金融领域、再到生物进化领域，每一个领域都充斥了随机的过程。

本章通过一种随机过程来研究后验概率分布的估计。该过程就是大名鼎鼎的马尔可夫链蒙特卡罗Markov chain Monte Carlo(MCMC)。本章将在后验概率模型中随机抽样进行后验概率估计，而不必像之前那样需要对模型的模型参数进行极大化处理。也不需要依赖具体的后验概率分布形式（比如正态分布等）。由于避免了正态假设，这对广义线性模型和多水平模型的后验概率分布估计很有帮助。当然，这样做带来的代价就是计算量的大大增加，完成一个估计可能需要较长的时间。

本章MCMC的估计是通过R语言rethinking包的map2stan函数来实现的，其实是使用的STAN软件。

## 8.1: MCMC

### 8.1.1 MCMC是什么

那MCMC到底是什么呢？《告别数学公式，图文解读什么是马尔可夫链蒙特卡罗方法》里面这样解释：MCMC方法是用来在概率空间，通过随机采样估算兴趣参数的后验分布。

蒙特卡罗本来就可以采样，马尔可夫链可以采样，为啥要将他们合在一起？下面给出两个动机，后面将从蒙特卡罗开始一直推到gibbs采样，来深入了解为什么需要MCMC。

### 8.1.2 为什么需要MCMC

动机一

假如你需要对一维随机变量$X$进行采样，X 的样本空间是${1,2,3}$ ，且概率分别是${1/2,1/4,1/4}$ ，实现的步骤为：首先根据各离散取值的概率大小对 $[0,1]$区间进行等比例划分，如划分为$[0,0.5],[0.5,0.75],[0.75,1]$ 这三个区间，再通过计算机产生$[0,1]$ 之间的伪随机数，根据伪随机数的落点即可完成一次采样。接下来，假如X是连续分布的呢，概率密度是$f(X)$ ，那该如何进行采样呢？你肯定会想到累积分布函数， $P(X<t)=\int_{-\infty}^{t}{f(x)}dx$，即在$[0,1]$ 间随机生成一个数$\alpha$，然后求使得使$P(x<t)=\alpha$ 成立的$t$，$t$即可以视作从该分部中得到的一个采样结果。这里有两个前提：一是概率密度函数可积；第二个是累积分布函数有反函数。假如条件不成立怎么办呢？MCMC就登场了。

动机二

假如对于高维随机变量，比如$\mathbb{R}^{50}$ ，若每一维取100个点，则总共要取$10^{10}$ ，而已知宇宙的基本粒子大约有$10^{87}$ 个，对连续的也同样如此。因此MCMC可以解决“维数灾难”问题。

## 8.2： 蒙特卡罗

### 8.2.1 引入

蒙特卡罗方法于20世纪40年代美国在第二次世界大战中研制原子弹的“曼哈顿计划”计划时首先提出，为保密选择用赌城摩纳哥的Monte Carlo作为代号。

[![qXjJV1.png](https://s1.ax1x.com/2022/04/06/qXjJV1.png)](https://imgtu.com/i/qXjJV1)

对于上图你如何求解圆的面积？当然知道圆的直径，或根据圆的方程进行积分很容易求解。也可以用如下方法进行简单近似：
[![qXjt56.png](https://s1.ax1x.com/2022/04/06/qXjt56.png)](https://imgtu.com/i/qXjt56)

我们可以在这个正方形内随机撒20个米粒，然后我们数一下有多少个米粒落在圆圈内，计算这部分比例，并乘以正方形的面积。如上图大概是3/4正方形的面积。

这个方法在我们无法知道形状的方程时很有用，如下图的蝙蝠：

[![qXjyVI.png](https://s1.ax1x.com/2022/04/06/qXjyVI.png)](https://imgtu.com/i/qXjyVI)

在一块长方形区域内随机抛掷点，蒙特卡罗方法能非常轻松地计算出该区域的近似值。

其上等价于如下公式：$面积=\int_{a}^{b}{f(x)}dx=\frac{b-a}{n}\sum\limits_{i=1}^{n}{f(x_i)}$,即求出高度的均值在乘以宽度，因为任何一个不规则图形的面积都等价于一个矩形的面积。

但是它隐含了一个假定，即$x$在$[a,b]$之间是均匀分布的，而绝大部分情况，$x$在$[a,b]$之间不是均匀分布的。可以表示为：$\int_{a}^{b}{\frac{f(x)}{q(x)}q(x)dx}$,这里把$q(x)$看做是x在区间内的概率分布函数，而把前面的分数部分看做一个函数，然后在$q(x)$下抽取$n$个样本，当n足够大时，可以采用均值来近似：$\sum\limits_{i=1}^{n}{\frac{f(x)}{q(x)}}$,这个形式就是蒙特卡罗方法的一般形式。

### 8.2.2 均匀分布

均匀分布是很容易采样的，比如在计算机中生成$[0,1]$ 之间的伪随机数序列，就可以看成是一种均匀分布。而我们常见的概率分布，无论是连续的还是离散的分布，都可以基于 $Uniform(0,1)$的样本生成。

### 8.2.3 拒绝接受采样（Acceptance-Rejection Sampling）

1.需求：已知分布的概率密度函数$f(x)$, ，产生服从此分布的样本$X$

2.准备工作：

需要一个辅助的“建议分布proposal distribution” $G$ （已知其概率密度函数$g(y)$ ）来产生候选样本。——由分布来产生候选样本，因此需要我们能够从$G$抽样。即我们必须能够生成服从此概率分布的样本 $Y$。比如可以选择均匀分布、正态分布。

还需要另一个辅助的均匀分布$U(0,1)$。

计算一个常数值$c$。——满足不等式$c*g(x)\ge f(x)$的最小值 c(当然，我们非常希望$c$接近于1)

3.开始样本生成：

从建议分布$G$抽样，得到样本$Y$ 。

从分布$U(0,1)$抽样，得到样本$U$。

如果$U\le \frac{f(Y)}{c*g(Y)}$，则令$X=Y$(接受$Y$),否则继续执行步骤1（拒绝）。

### 8.2.4 蒙特卡罗方法小结

使用接受-拒绝采样，我们可以解决一些概率分布不是常见的分布的时候，得到其采样集并用蒙特卡罗方法求和得到。但是接受-拒绝采样也只能部分满足我们的需求，在很多时候我们还是很难得到我们的概率分布的样本集。比如之前的第一个问题有时可以解决，但又会产生另一个问题：

1.对于一些二维分布$p(x,y)$，我们只能得到条件分布 $p(x|y),p(y|x)$，却不能得到二维分布的一般形式；

2.对于复杂非常见分布$p(x_1,x_2,...,x_n)$，我们很难找到合适的$q(x),c$。

要想将蒙特卡罗方法作为一个通用的采样模拟求和的方法，还的需马尔科夫链的帮忙。

## 8.3： 马尔可夫链

### 8.3.1 马尔可夫链概述

马尔科夫链定义本身比较简单，它假设某一时刻状态转移的概率只依赖于它的前一个状态。即$$P(X^{t+1}|X^1,..,X^t)=P(X^{t+1}|X^t)$$

因为某一时刻状态转移只依赖于它的前一个状态，那么我们只要能求出系统中任意两个状态之间的转换概率，最终可得到状态转移概率矩阵。如下图孩子的心情的转变

[![qjiQx0.png](https://s1.ax1x.com/2022/04/06/qjiQx0.png)](https://imgtu.com/i/qjiQx0)


转移概率矩阵为:

$$P=
\left[
 \begin{matrix}
0.6 & 0.2 & 0.2\\
0.3 & 0.4 & 0.3\\
0 & 0.3 & 0.7
\end{matrix}
\right]$$



### 8.3.2 马尔可夫链模型状态转移矩阵的性质

如果一个非周期的马尔科夫有状态转移矩阵$P$ ，并且他的任何两个状态是连通的，那么$\lim\limits_{n \rightarrow +\infty} P_{ij}^{n}$与i无关，我们有：

1.$\lim\limits_{n \rightarrow +\infty} P_{ij}^{n}=\pi(j)$

2.$$\lim\limits_{n \rightarrow +\infty} {P}^{n}=
\left[
\begin{matrix}
 \pi(1)      & \pi(2)      & \cdots & \pi(j)  & \cdots     \\
 \pi(1)      & \pi(2)      & \cdots & \pi(j)  & \cdots       \\
 \vdots & \vdots &  \vdots&\ddots & \vdots \\
\pi(1)      & \pi(2)      & \cdots & \pi(j)  & \cdots       \\
 \vdots & \vdots &  \vdots&\ddots & \vdots\\
\end{matrix}
\right]
$$

3.$\pi(j)=\sum \limits_{i=0}^{\infty}{\pi(i)P_{ij}}$

4.$\pi$是方程$\pi P=\pi$唯一非负解，其中$\pi=[\pi(1),\pi(2),...,\pi(j),...]\sum \limits_{i=1}^{\infty}{\pi(i)}=1$,$\pi$称为马氏链的平稳分布。

注意：

1.非周期的马尔可夫链：这个主要是指马尔可夫链的状态转化不是循环的，如果是循环的则永远不会收敛。幸运的是我们遇到的马尔可夫链一般都是非周期性的。用数学方式表述则是：对于任意某一状态$i,$, $d$为集合${n|n\ge 1,P_{ij}^{n}>0}$ 的最大公约数，如果$d=1$ ，则该状态为非周期的。

2.任何两个状态是连通的：这个指的是从任意一个状态可以通过有限步到达其他的任意一个状态，不会出现条件概率一直为0导致不可达的情况，即$P^n$ 中任意一个元素都大于零。

3.马尔可夫链的状态数可以是有限的，也可以是无限的。因此可以用于连续概率分布和离散概率分布。

4.我们用$X_i$表示在马氏链上跳转第$i$ 步后所处的状态，如果
$\lim\limits_{n \rightarrow +\infty} P_{ij}^{n}=\pi(j)$ 存在，很容易证明以上定理的第三个结论。由于
$$P(X_{n+1}=j)=\sum \limits_{i=0}^{\infty}{P(X_n=i)}P(X_{n+1}=j|X_n=i)
=\sum \limits_{i=0}^{\infty}{P(X_n=i)}{P_{ij}}$$
两边去极限就可以得到：

$$\pi(j)=\sum \limits_{i=0}^{\infty}{\pi(i)P_{ij}}$$ 
5. 由马氏链收敛的定理, 概率分布$\pi_i(x)$ 将收敛到平稳分布$\pi(x)$。假设到第$n$ 步的时候马氏链收敛，则有$X_n \sim \pi(x),X_{n+1} \sim \pi(x),X_{n+2} \sim \pi(x),...$，所以$X_n,X_{n+1},X_{n+2},...\pi(x)$ 都是同分布的随机变量，当然他们并不独立。如果我们从一个具体的初始状态$x_{0}$开始, 沿着马氏链按照概率转移矩阵做跳转，那么我们得到一个转移序列$X_0,X_1,X_2,...X_n,X_{n+1},...$，由于马氏链的收敛行为，$X_n,X_{n+1},...$都将是平稳分布$\pi(x)$ 的样本。

### 8.3.3 基于马尔可夫链采样

如果我们得到了某个平稳分布所对应的马尔可夫链状态转移矩阵，我们就很容易采用出这个平稳分布的样本集。

首先，基于初始任意简单概率分布比如高斯分布$\pi_0(x)$ 采样得到状态值$x_0$，基于条件概率分布$P(x|x_0)$ 采样状态值$x_1$ ，一直进行下去，当状态转移进行到一定的次数时，比如到 $n$次时，我们认为此时的采样集$(X_n,X_{n+1},...)$ 即是符合我们的平稳分布的对应样本集，可以用来做蒙特卡罗模拟求和了。

算法如下：

1.输入马尔可夫链状态转移矩阵$P$ ，设定状态转移次数阈值$n_1$，需要的样本个数$n_2$ ；

2.从任意简单概率分布采样得到初始状态值$x_0$ ；

3.for $t=0$ to $n_1+n_2-1$: 从条件概率分布$P(x|x_t)$ 中采样得到样本$x_{t+1}$；

4.样本集$(X_n,X_{n+1},...)$即是符合我们的平稳分布的对应样本集。

### 8.3.4 马尔可夫链采样小结

如果假定我们可以得到我们需要采样样本的平稳分布所对应的马尔可夫链状态转移矩阵，那么我们就可以用马尔可夫链采样得到我们需要的样本集，进而进行蒙特卡罗模拟。

但是一个重要的问题是，随意给定一个平稳分布$\pi$ ,如何得到它所对应的马尔可夫链状态转移矩阵P呢？MCMC是时候出现了。

## 8.4： 马尔可夫链蒙特卡罗算法

### 8.4.1 马尔可夫链的细致平稳条件(Detailed Balance Condition)

在解决从平稳分布$\pi$, 找到对应的马尔可夫链状态转移矩阵$P$ 之前，我们还需要先看看马尔可夫链的细致平稳条件。定义如下：

如果非周期马尔可夫链状态转移矩阵$P$和概率分布$\pi(x)$对所与的$i,j$满足：
$$\Pi(i)P(i,j)=\Pi(j)P(j,i)  \   for\  all\  i,j$$
则称概率分布$\pi(x)$是状态转移矩阵$P$ 的平稳分布(Stationary Distribution)。

上述只是个充分条件，当分布是二维时，此条件是充要的，但3维以上时，就不是了。

从细致平稳条件可以得到，只要我们找到了可以使概率分布$\pi(x)$满足细致平稳分布的矩阵$P$ 即可。这给了我们寻找从平稳分布$\pi$, 找到对应的马尔可夫链状态转移矩阵$P$的新思路。

不过不幸的是，我们很难找到合适的矩阵$P$ 满足细致平稳条件。

### 8.4.2 MCMC采样

由于一般情况下，目标平稳分布$\pi(x)$ 和某一个马尔可夫链状态转移矩阵$Q$ 不满足细致平稳条件，即：
$$\pi(i)Q(i,j) \neq \pi(j)Q(j,i) $$

以下记号表达同一个意思：$$Q(i,j) \Leftrightarrow Q(j|i) \Leftrightarrow Q(i \rightarrow j)$$
我们引入一个$\alpha(i,j)$,使上式可以取等号。
$$\pi(i)Q(i,j)\alpha(i,j) = \pi(j)Q(j,i)\alpha(j,i) $$
怎样才能成立呢，其实很简单，按照对称性：
$$\alpha(i,j)=\pi(j)Q(j,i);\pi(i)Q(i,j)=\alpha(j,i)$$
然后我们就可以得到了分布$\pi(x)$ 的马尔可夫链状态转移矩阵$P(i,j)=Q(i,j)\alpha(i,j)$

其中$\alpha(i,j)$一般称之为接受率，取值在$[0,1]$之间，可以理解为一个概率值。这很像接受-拒绝采样，那里是以一个常用分布通过一定的接受-拒绝概率得到一个非常见分布， 这里是以一个常见的马尔可夫链状态转移矩阵$Q$通过一定的接受-拒绝概率得到目标转移矩阵$P$ ,两者的解决问题思路是类似的。

MCMC采样算法如下：

1.输入任意给定的马尔可夫链状态转移矩阵$Q$ ，目标平稳分布$\pi(x)$，设定状态转移次数阈值$n_1$ ，需要的样本数$n_2$;

2.从任意简单概率分布得到初始状态值$x_0$；

3.for $t=0$ to $n_1+n_2-1$: 

\  a.从条件概率分布$Q(x|x_t)$ 中采样得到样本$x_*$

\  b.从均匀分布中采样$U \sim [0,1]$

\  c.如果$u<\alpha(x_t,x_*)=\pi(x_*)Q(x_*,x_t)$,则接受$x_t \rightarrow x_*$,即$x_{t+1}=x_*$

\  d.否则不接受转移，$x_{t+1}=x_t$

但是这个采样算法还是比较难在实际中应用，因为在第三步中，由于$\alpha(x_t,x_*)$可能非常的小，比如0.1，导致我们大部分的采样值都被拒绝转移，采样效率很低。有可能我们采样了上百万次马尔可夫链还没有收敛，也就是上面这个$n_1$要非常非常的大，这让人难以接受，怎么办呢？这时就轮到我们的M-H采样出场了。

```{r}
#离散状态下的MCMC采样

#1.pi：平稳分布(相对于连续中的f(x))
pi <-  array(c(0.5,0.2,0.3))

#2.Q任意一个马尔可夫状态转移矩阵
q1 <- runif(3)
q2 <- runif(3)
q3 <- runif(3)
Q <- matrix(c(q1/sum(q1),
              q2/sum(q2),
              q3/sum(q3)),nrow = 3,byrow = TRUE)
apply(Q,1,sum)

#3.构造循环
N <- 1000 #设定状态转移次数
Nlmax <-  100000 #需要的样本数量
T <- N + Nlmax 

mcmc <- function(pi,Q){
  x0 <- sample(1:length(pi),1)#初始状态值
  result <- rep(x0,T)
  t <- 1
  while(t < T){
    t <- t + 1
    #从多项式分布中任意采集一个样本(相对于从g(x)中抽取样本)
    x_cur <- which.max(rmultinom(1, size = 1, 
                                         prob = Q[result[t - 1],]))
    acc <- pi[x_cur] * Q[x_cur,result[t - 1]]#计算接收概率
    u <- runif(1)
    if(u < acc){
      result[t] <- x_cur
    }
    else{
      result[t] <- result[t-1]
    }
  }
  return(result)
}

a <- mcmc(pi,Q)[0:N]
plot(a)
prop.table(table(a))

#抽取到的样本服从Pi分布
result_mcmc <- mcmc(pi,Q)[N + 1:T]
prop.table(table(result_mcmc))
```
```{r}
#连续状态下的MCMC采样

#用卡方分布去近似正态分布

#1.目标分布的密度函数
f <- function(x){
  D <- dnorm(x,mu,sigma)
  return(D)
}

#2.采集次数
N <- 10000
mu <- 3
sigma <- 2
x <- numeric(N)#生成10000个0
x[1] <- round(rchisq(1,df=3))#初始化提议分布
k <- 0
u <- runif(N)

#3.构造循环
for(i in 2:N)
{
  y <- round(rchisq(1,df = x[i-1])) #候选点
  alpha <- f(y)*dchisq(x[i-1],df = y) 
  if (u[i] <= alpha) 
    x[i] <- y
  else {
    x[i] <- x[i-1]
    k <- k+1 #y is rejected
  }  
}
print(k)
table(x)
plot(x,dnorm(x,mu,sigma))
hist(x)
```


##  8.5：Metropolis采样算法

###  8.5.1 Metropolis采样算法的思路

Metropolis采样算法的基本思路是：从一个已知的形式较为简单的分布中采样，并以一定的概率接受这个样本作为目标分布的近似样本。假设我们需要采集一个复杂分布$\pi(x)$的样本，转移概率矩阵$P$以$\pi(x)$为平稳分布。现在我们有一个形式较为简单的对称分布$\theta(x)$，转移概率矩阵$Q$以$\theta(x)$为平稳分布，从$\theta(x|x_{n-1})$中采样得到一个候选样本$\hat{x}$，以一定的概率选择接受或拒绝这个候选样本。一般这个接受的概率定为$\alpha=min(1,\frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)})$，当随机生成的一个概率值小于指定的概率时，接受这个候选样本，否则拒绝这个候选样本并令$x_n=x_{n-1}$。

从分布$\theta(x|x_{n-1})$中采出的样本为什么可以作为$\pi(x)$的样本的近似呢？下面给出一点理论上的支撑。

$\theta(x)$的转移概率矩阵为Q，随机变量从状态$s_i$转移到$s_j$的转移概率为$Q_{ij}$，随机变量从状态$s_i$转移到$s_j$的接受概率为$\alpha_{ij}$，我们借助于$Q_{ij}$和$\alpha_{ij}$得到的转移概率$P_{ij}$和$Q_{ij}$、$\alpha_{ij}$有如下关系：：
$$ P_{ij} =\alpha_{ij} *Q_{ij} $$

只要满足：保证概率矩阵P满足细致平稳条件$\Pi(i)P_{ij}=\Pi(j)P_{ji}$,那么P的平稳分布就是目标分布$\Pi(x)$，马尔可夫收敛后的样本也是目标分布$\Pi(x)$的样本。

因此，转移概率矩阵P的平稳分布为$\Pi(x)$，以上述方式获得的马尔可夫收敛后的样本序列为目标分布$\Pi(x)$的近似样本。

###  8.5.2 Metropolis采样算法步骤

step1.初始化：t=0，随机生成一个$x_0$赋值给当前的$x_t$，迭代终止条件为$t=T$

step2.令$t=t+1$，从条件概率分布$\Theta(x|x_{t-1})$中生成候选样本$\hat{x}$

step3.计算接受概率$\alpha$,$\alpha=min(1,\frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)})$

step4.从均匀分布中生成一个随机数$\alpha_t$

step5.若$\alpha_t \le \alpha$，则接受候选样本，$x_t=\hat{x}$,否则，拒绝候选样本并令$x_t=x_{t-1}$

step6.若$t=T$，停止迭代，否则回到第2步继续迭代。

停止迭代后，生成了样本序列，根据需要截取尾部的n个样本，这n个样本可以近似地认为是从目标分布中采样得到的。
```{r}
#以卡方分布为提议分布，目标分布为正态分布

f <- function(x)#定义正态分布
{
  D<- dnorm(x,mu,sigma)
  return(D)
}

N<- 1000
mu<- 3
sigma<- 2
x<-numeric(N)
x[1]<- rchisq(1,df=1)#初始化值
k<- 0#拒绝采样的次数
u<- runif(N)#从均匀分布中随机生成随机数

#进行循环采样
for (i in 2:N)
{
  y<- rchisq(1,df=x[i-1])#初始化提议分布
  pro<- f(y)*dchisq(x[i-1],df=y)
  cur<- f(x[i-1])*dchisq(y,df=x[i-1])
  
  if(u[i]<=pro/cur){
    x[i]<-y
  }
    
  else{
    x[i]<-x[i-1]
    k<- k+1
  }
    
}
print(k)

#绘制路径图
plot(x,f(x))
hist(x)
```


## 8.6 国王与岛屿

一个很爱民的国王拥有10个岛屿的领地，这10个岛屿相互环绕组成一个环。(如下图)

[![bLRYAH.png](https://s1.ax1x.com/2022/03/14/bLRYAH.png)](https://imgtu.com/i/bLRYAH)

每个岛屿的大小不同，每个岛屿上的人口也不同，第一个岛屿最小，人口最少，第二个人口第二少，以此类推，到最后一个岛屿，其最大，人口也最多，是第一个岛人口数的10倍。这位爱民的国王去视察他的子民，但是为了一视同仁，避免偏见，他决定在每个岛上停留的时候应该和该岛的人口数成正比，人口越多的岛（如第10个岛），应该停留时间最长。

当然，这也不难，做一个年度计划，按照人口数大小确定在每一个岛上待的时间即可。

但是，这为国王并不喜欢死板而又长远的计划，他只希望当他在一个岛上待了一段时间后，再临时决定去其他岛，而且他只会去邻近的岛，不会跨岛移动。只要最后保证在某个岛上待的总时间和岛上人口数成比例即可。

那么，这位国王该怎么做呢？？

还好，这位国王有一位聪明的大臣叫Metropolis，他很快找到了一种方法，能够在不作出行计划的情况下，达到国王的要求。他是这么做的：

1）不管国王现在在哪个岛上，每待完一周后，他就要考虑下一周的行程：要么在该岛上继续待一周，要么去邻近的一个岛屿。如果是去邻近的岛屿，他会通过掷硬币来决定下周去相邻两个岛中的一个。如果硬币正面朝上，那么他会按照顺时针方向移动到邻近岛上；如果反面朝上，他会按照逆时针方向移动到邻近岛上。这个有掷硬币决定的岛，我们称之为”目标岛”。

2）那么为了决定国王是否移动换岛，他是这么做的。按照目标岛上的人口比例把一些贝壳放在了一个黑色袋子中；比如，如果他通过掷硬币决定应该去9号岛，那么他就把9个贝壳放在袋子中。同样的，他按照当前岛上人口比例把一些石子放在同一个袋子中；比如他现在在10号岛，那么他在袋子中又加入了10个石子。

3）如果袋子中贝壳比石子多，那么国王就会毫不犹豫的去目标岛屿。但是如果贝壳比石子少，他就会按照贝壳的数量来丢掉袋子中的石子，比如袋子中有4个贝壳和6个石子，那么他会丢带4个石子，最终袋子中剩余4个贝壳和（6-4）= 2个石子。然后他在袋子中随机抽取一个物体，如果是贝壳，那么他就会移动到目标岛屿；而如果是石子，他变会在该岛上继续待一周。

这个过程看似很复杂，但它确实十分有效。国王每次移动看起来是随机的，要么接着待在该岛，要么随机去邻近岛屿。但是长期过程来看，他达到了目的：不需要制定死板的长期行程规划，最终在每个岛上停留的时间和该岛上的人口数量成正比！

下面我们通过代码来模拟这一过程。下面的短代码模拟国王一系列的访问位置，模拟的结果存在变量position中：

```{r}
num_weeks <- 100000  #取100000个数
positions <- rep(0,num_weeks)#取100000个0
head(positions)
```
```{r}
current <-10 #起始岛屿，这里设置的为最大的10号岛屿
a<-c()
for( i in 1:num_weeks){
  #记录当前的位置
   positions[i] <- current
  # 掷硬币决定去向
   proposal <- current + sample(c(-1,1),size = 1)
  # 连接环状首尾，保证编号是在1-10之间循环
   #如果得到的是岛屿“0”，则自动切换到岛屿10
   if(proposal<1) proposal <- 10
   #如果得到的是岛屿“11”，则自动切换到岛屿1
   if(proposal>10) proposal <- 1        
  #决定去还是留
  prob_move <- proposal/current
  #抽取一个[0,1]上的随机变量，如果随机数小于下一个岛屿编号和当前岛屿编号的比值，国王就会出发前往下一个岛屿
  current <- ifelse(runif(1) < prob_move, proposal, current)
  a<- append(a,current)
  
}

```

[![bLbB7t.png](https://s1.ax1x.com/2022/03/14/bLbB7t.png)](https://imgtu.com/i/bLbB7t)

左图显示的国外在最初100个周内所处的岛，看起来是杂乱无章，没有规律可循的。但是当该过程进行10万周后，你会发现最终在每个岛屿上停留的时间和岛屿标号（即人口数）成正比，如右图。

实际上，如果国王不是选择邻近岛屿，而是随机选择任意岛屿，上述结果也依旧成立。只要按照目标岛屿和当前岛屿人口数的比例来作为移动的概率，最后结果都是一样的，即结果收敛。甚至即便国王不知道他一共有多少的岛屿，上述方法依旧可行。所以，只要国王知道当前岛屿人口和目标岛屿人口，照此移动即可，不在需要知道之前或者之后的其他岛屿的人口数！这就是一个简化的马尔科夫链蒙特卡罗！

上述例子中实现MCMC的方法也就叫做Metropolis算法，通过它可以在一个未知或者极其复杂的分布中进行高效抽样。

其中“岛”就是概率分布的参数值，可以是离散的，也可以是连续的；“人口数”就是每一个参数值的后验概率；“周”是模型中联合后验概率分布的样本。通过抽样就可以估计后验概率分布，进而可以进行参数估计等其他应用。

## 8.7 Gibbs抽样

从未知分布的后验概率中抽样的方法有很多种，但是Metropolis算法是其他抽样方法的始祖。除了Metropolis算法，还有Gibbs抽样和Hamiltonian抽样。这两种方法在贝叶斯统计中也经常用到。

###  8.7.1 Gibbs抽样

Metropolis算法中从A移动到B和从B移动到A的概率是相等（对称）的。该方法更广泛的应用是Metropolis-Hastings方法，它不要求双向移动概率相等，即在上述例子中，国王使用的硬币可以是一个“不公平”的硬币。

双向移动概率的不对称在我们的实际应用很重要，能够使我们更容易处理一些有边界的参数，比如标准差。而处理这种不对称最常用的方法就是“Gibbs抽样”。它是Metropolis-Hastings方法的一个改进，能够更加高效的抽样。在实际使用中，很多贝叶斯模型软件，比如BUGS和JAGS都是使用的Gibbs抽样方法。

### 补充：

1、重新寻找合适的细致平稳条件

在上面我们提到了如果非周期马尔可夫链的状态转移P和概率分布$\Pi(x)$对于所有的i,j满足：$\Pi(i)P(i,j)=\Pi(j)P(j,i)$，则称概率分布$\Pi(x)$是状态转移矩阵P的平稳分布。

在Metropolis中我们通过引入接受率使得细致平稳条件满足。现在我们换一个思路。

从二维的数据分布开始，假设$\pi(x1,x2)$ 是一个二维联合数据分布，观察第一个特征维度相同的两个点$A(x_1^{(1)},x_2^{(1)})$和$B(x_1^{(1)},x_2^{(2)})$，容易发现下面两式成立：

$$π(x_1^{(1)},x_2^{(1)})π(x_2^{(2)}|x_1^{(1)})=π(x_1^{(1)})π(x_2^{(1)}|x_1^{(1)})π(x_2^{(2)}|x_1^{(1)})$$
$$π(x_1^{(1)},x_2^{(2)})π(x_2^{(1)}|x_1^{(1)})=π(x_1^{(1)})π(x_2^{(2)}|x_1^{(1)})π(x_2^{(1)}|x_1^{(1)})$$ 
由于两式的右边相等，因此我们有：
$$π(x_1^{(1)},x_2^{(1)})π(x_2^{(2)}|x_1^{(1)})=π(x_1^{(1)},x_2^{(2)})π(x_2^{(1)}|x_1^{(1)})$$
也就是：
$$\pi(A)\pi(x_2^{(2)}|x_1^{(1)})=\pi(B)\pi(x_2^{(1)}|x_1^{(1)})$$
观察上式再观察细致平稳条件的公式，我们发现在$x_1=x_1^{(1)}$这条直线上，如果用条件概率分布$π(x_2|x_1^{(1)})$作为马尔可夫链的状态转移概率，则任意两个点之间的转移满足细致平稳条件！同样的道理，在$x_2=x_2^{(1)}$这条直线上，如果用条件概率分布$π(x_1|x_2^{(1)})$作为马尔可夫链的状态转移概率，则任意两个点之间的转移也满足细致平稳条件。那是因为假如有一点$C(x_1^{(2)},x_2^{(1)})$,我们可以得到：
$$\pi(A)\pi(x_1^{(2)}|x_2^{(1)})=\pi(C)\pi(x_1^{(1)}|x_2^{(1)})$$
基于上面的发现，我们可以这样构造分布$π(x_1,x_2)$的马尔可夫链对应的状态转移矩阵P：
$$ P(A→B)=π(x_2^{(B)}|x_1^{(1)}) 
if X_1^{(A)}=X_1^{(B)}=X_1^{(1)}$$
 
$$P(A→C)=π(x_1^{(C)}|x_2^{(1)}) 
if X_2^{(A)}=X_2^{(C)}=X_2^{(1)}$$
$$ P(A→D)=0else$$
有了上面这个状态转移矩阵，我们很容易验证二维平面上的任意两点E,F，满足细致平稳条件时：
$$π(E)P(E→F)=π(F)P(F→E)$$
于是这个二维空间上的马氏链将收敛到平稳分布$\pi(x,y)$

#### 8.7.1.1 二维的Gibbs采样

利用上面找到的状态转移矩阵，我们就得到了二维Gibbs采样，这个采样需要两个维度之间的条件概率。具体过程如下：

1）输入平稳分布$π(x_1,x_2)$，设定状态转移次数阈值$n_1$，需要的样本个数$n_2$

2）随机初始化初始状态值$x_1^{(0)}$和$x_2^{(0)}$

3）for $t=0$ to $n_1+n_2−1$: 

　　a) 从条件概率分布$P(x_2|x_1^{(t)})$中采样得到样本$x_2^{(t+1)}$
　　　　　
　　b) 从条件概率分布$P(x_1|x_2^{(t+1)})$中采样得到样本$x_1^{(t+1)}$
　　　　　
样本集
$${(x_1^{(n_1)},x_2^{(n_1)}),(x_1^{(n_1+1)},x_2^{(n_1+1)}),...,(x_1^{(n_1+n_2-1},x_2^{(n_1+n_2-1)})}$$
即为我们需要的平稳分布对应的样本集。

整个采样过程中，我们通过轮换坐标轴，采样的过程为：
$$(x_1^{(1)},x_2^{(1)})→(x_1^{(1)},x_2^{(2)})→(x_1^{(2)},x_2^{(2)})→...→(x_1^{(n_1+n_2-1)},x_2^{(n_1+n_2-1)})$$

用下图可以很直观的看出，采样是在两个坐标轴上不停的轮换的。当然，坐标轴轮换不是必须的，我们也可以每次随机选择一个坐标轴进行采样。不过常用的Gibbs采样的实现都是基于坐标轴轮换的。

[![qrCVdU.png](https://s1.ax1x.com/2022/03/28/qrCVdU.png)](https://imgtu.com/i/qrCVdU)

#### 8.7.1.2 多维的Gibbs采样

上面的这个算法推广到多维的时候也是成立的。比如一个n维的概率分布$\pi(x_1,x_2,...x_n)$，我们可以通过在n个坐标轴上轮换采样，来得到新的样本。对于轮换到的任意一个坐标轴$x_i$上的转移，马尔科夫链的状态转移概率为$P(x_i|x_1,x_2,...,x_{i−1},x_{i+1},...,x_n)$，即固定n−1个坐标轴，在某一个坐标轴上移动。

具体的算法过程如下：

1）输入平稳分布$\pi(x_1,x_2，...,x_n)$或者对应的所有特征的条件概率分布，设定状态转移次数阈值$n_1$，需要的样本个数$n_2$

2）随机初始化初始状态值$(x_1^{(0)},x_2^{(0)},...,x_n^{(0)})$

3）for $t=0$ to $n_1+n_2−1$:  

　a) 从条件概率分布$P(x_1|x_2^{(t)},x_3^{(t)},...,x_n^{(t)})$中采样得到样本$x_1^{t+1}$
　
　b) 从条件概率分布
　$P(x_2|x_1^{(t+1)},x_3^{(t)},...,x_n^{(t)})$中采样得到样本$x_2^{(t+1)}$
　　　　　
　c)...

　d) 从条件概率分布$P(x_j|x_1^{(t+1)},x_2^{(t+1)},...,x_{j-1}^{(t+1)},x_{j+1}^{(t)},...,x_n^{(t)})$中采样得到样本$x_j^{(t+1)}$

　e)...

　f) 从条件概率分布$P(x_n|x_1^{(t+1)},x_2^{(t+1)},...,x_{n-1}^{(t+1)})$中采样得到样本$x_n^{t+1}$
　
样本集$$(x_1^{(n_1)},x_2^{(n_1)},...,x_n^{(n_1)}),...,(x_1^{(n_1+n_2-1},x_2^{(n_1+n_2-1)},...,x_n^{(n_1+n_2-1)})$$,即为我们需要的平稳分布对应的样本集。

整个采样过程和Lasso回归的坐标轴下降法算法非常类似，只不过Lasso回归是固定n−1个特征，对某一个特征求极值。而Gibbs采样是固定n−1个特征在某一个特征采样。

同样的，轮换坐标轴不是必须的，我们可以随机选择某一个坐标轴进行状态转移，只不过常用的Gibbs采样的实现都是基于坐标轴轮换的。

#### 8.7.1.3 Gibbs采样的缺点

Gibbs方法的缺点是，需要联合先验概率，而先验概率的选择对很对不太了解贝叶斯的人来说往往很难接受。其次，随着模型变得复杂，比如含有成百上千个参数的模型，那么Gibbs的抽样变得效率非常低。这时，我们就应该考虑其他的抽样方法了。

#### 8.7.1.4 Gibbs采样的小结

Gibbs采样是接受概率为1的Metropolis算法，是MCMC算法的分解形式：

假设我们有多个随机数组成的联合分布$p(\beta,\gamma,\sigma,...,Z)$,我们给定其中任何一个分布，如$p(Z)$,$P(\sigma | Z)$,$P(\gamma|....)$依次进行下去，可以将上述的联合分布拆分成多个条件分布，进行联合抽取过程。其中的每一个条件分布都可记作是M-H算法，这就是Gibbs抽样的过程。

## 8.8 Hamiltonian蒙特卡罗

“当通过随机的过程做一件事的时候，似乎也总能通过非随机的方式来做，只不过非随机的方式需要我们更多的智慧”

Metropolis和Gibbs的方法都是高度随机的过程，通过尝试不同的新的参数，然后和当前值比较。只不过，Gibbs方法使用先验概率，相对降低了一定的随机性，以此换来了更高的效率。

相比之下，Hamiltonian方法（HMC）更为高效，只需要更少的抽样便可很好的对后验概率分布进行描述，特别是在参数很多的时候，Hamiltonian方法的效率远远胜于其他方法。

Hamiltonian/Hybrid Monte Carlo (HMC) 是一种 MCMC 方法，它采用物理系统动力学而不是概率分布来提出马尔可夫链中的未来状态。这允许马尔可夫链更有效地探索目标分布，从而更快地收敛。

如何使用Hamiltonian dynamics 构造一个MCMC方法。

1.	先针对我们想要进行采样的目标分布定义对应的Hamiltion函数；

2.	引入目标变量（“位置”变量），还必须引入“动量”变量（一般是与位置变量独立的高斯分布）；

3.	通过leapfrog方法计算新的状态，然后用Metroplis算法进行更新。


###  8.8.1 哈密顿力学

哈密顿动力学在非物理的情况下使用时，位置变量相当于我们的目标变量，势能是-log(目标变量概率密度函数),动量变量是人为引入的。

Hamiltonian dynamics的刻画是在d维的位置向量q和d维的动量向量p,因此完整的状态空间是2d维的。


1.Hamiltonian对p和q的偏导数决定了q和p如何随着时间变化，根据哈密顿方程：
$$ \frac{dq_i}{dt}=\frac{\partial H}{\partial p_i}$$
$$ \frac{dp_i}{dt}=-\frac{\partial H}{\partial q_i}$$
对于所有的$i = 1……d$。

通常情况下，HMC当中可以将哈密顿方程写成如下形式
$$ H(q,p)=U(q)+K(p)$$

这里的$U(q)$被称为势能，并且被定义为我们想要采样的参数 q对应分布的负对数概率密度加上一个常数。$K(p)$被称作动能，通常被定义为$K(p)=P^{T} M^{-1} P/2$，其中，M为对称、正定的质量矩阵，大多数情况下是一个对角矩阵，更经常是一个标量乘以单位矩阵，这种情况下，$K(p)$就是一个均值为0，协方差矩阵为M的高斯分布。

2.哈密顿力学的性质

可逆性：保证目标分布的不变性

Hamiltionian不变：

保持体积不变：在更新MH更新时，不需要考虑积分空间体积不变，概率质量得以保证

### 8.8.2 来自哈密顿力学的MCMC

使用哈密顿力学来为分布采样，需要将分布的概率密度转化成势能函数，以及引入与原始目标变量相应的“动量”，我们可以通过先对动量进行再次采样，然后使用Metropolis方法更新哈密顿力学来寻找建议点，这样就可以构造一个markov chain。

通常将采样的分布和势能函数通过cannonical（规范）分布联系起来，在物理系统中，给一些对状态x的能量函数E(X),那么状态的cannonical分布的概率或概率密度是：$$P(x)=\frac{1}{Z}exp(-E(x)/T)$$
Hamiltonian是“位置q”和“动量p”联合状态的能量函数，因此他们的联合分布是：
$$P(q,p)=\frac{1}{Z}exp(-H(q,p)/T)$$ 
如果$$ H(q,p)=U(q)+K(p)$$，则
$$P(q,p)=\frac{1}{Z}exp(-U(q)/T)exp(-K(p)/T)$$ 

由以上可见，对于能量函数$U(q)$和 $K(p)$的每个canonical分布，p和q是独立的。我们用q代表目标变量，引入p以使哈密顿力学可以运行。

在贝叶斯统计中，我们经常想知道的是模型参数的后验分布，因此，在这里，后验分布就是这里的位置变量q。我们可以使用下面的势能函数来吧后验分布表示为canonical分布：
$$U(q)=-log[\pi(q)L(q|D)]$$

### 8.8.3 模拟哈密顿动力学——Leap Frog 方法

哈密顿方程描述了物体在时间上的运动，它是一个连续变量。为了在计算机上数值模拟哈密顿动力学，有必要通过离散时间来近似哈密顿方程。这是通过将区间T拆分为一系列较小的长度区间$\epsilon$来完成的。使用一些小的步长$\epsilon$，从时刻0状态开始，迭代计算$\epsilon,2\epsilon,...$时的状态。Leap Frog 方法依次更新动量和位置变量，首先模拟一小段时间的动量动力学$\frac{\epsilon}{2}$，然后在稍长的时间间隔内模拟位置动力学$\epsilon$，然后在另一个小时间间隔内完成动量模拟.具体来说，Leap Frog 方法如下：

1. 时间走半步更新动量变量：
$$p_i(t+\epsilon/2)=p_i(t)-(\epsilon/2) \frac{\partial U}{\partial q_i(t)}$$
2.及时整步更新位置变量
$$ q_i(t+ \epsilon)=q_i(t)+\epsilon \frac{\partial K}{\partial p_i(t+\epsilon/2)}$$
3.将剩余的半步及时完成更新动量变量
$$ p_i(t+\epsilon)=p_i(t+\epsilon/2)-(\epsilon/2)\frac{\partial U}{\partial q_i(t+\epsilon)}$$
可以运行 Leap Fog 方法L以模拟$L \times \epsilon$单位时间内的动态。这种特殊的离散化方法具有许多特性，使其优于其他近似方法，如欧拉方法，特别是在 MCMC 中使用。

```{r}
library(animation)
epsilon = 0.3; L = 20#步长为0.3，轨迹步长为20步
q_leapfrog = vector(length = L + 1)
p_leapfrog = vector(length = L + 1)
q_leapfrog[1] = 0
p_leapfrog[1] = 1#初始值为1，其他都是0

for (i in 2:(L+1)) 
{
  p_half = p_leapfrog[i - 1] - epsilon/2 * q_leapfrog[i - 1]#动量先更新半步
  q_leapfrog[i] = q_leapfrog[i - 1] + epsilon * p_half#新的动量值把位置更新一步
  p_leapfrog[i] = p_half - epsilon/2 * q_leapfrog[i]#使用上面新的位置变量把动量变量在更新另外半步
}

plot(q_leapfrog, p_leapfrog, xlim = c(-2, 2), ylim = c(-2, 2),
     xlab = "q(position)", ylab = "p(momentum)", type = "l",
     main = "leapfrog")

#animation(动画图)
library(animation)
saveGIF(
  {
    ani.options(interval = 0.1)#间隔为0
    for (i in 1:(L+1)) 
    {
      plot(q_leapfrog, p_leapfrog, type = "l", xlim = c(-2, 2), ylim = c(-2,2),
           xlab = "q(position)", ylab = "p(momentum)",
           col = "red")
      
      lines(q_leapfrog[1:i], p_leapfrog[1:i], xlim = c(-2, 2), 
            ylim = c(-2, 2), xlab = "q(position)", 
            ylab = "p(momentum)", type = "b",col = "blue")
    }
  }
  ,movie.name = "leapfrog.gif")
```


### 8.8.3 Hamiltonian蒙特卡罗

HMC仅仅用于在$R^d$上的连续分布，且其概率密度可以计算的情况下。对于动量，我们假设在任何区域概率密度都是非零的,我们也必须可以计算log(密度函数)的偏导数。这些偏导数必须存在，除了在一些概率为0的点（这种情况下，返回值为任意值）。

通过指定势能函数$U(q)$，可以得到目标变量q的概率分布，之后通过HMC来对q 和p的联合分布进行采样。我们可以选择和q相独立的变量p的分布，通过制定动能K（p），得到我们所需要的变量p的分布。目前的实践中，我们一般使用二次形式的动量，这导致p是一个均值为0的多变量高斯分布。更经常的是，指定p的个分量（mi）是相互独立的（即协方差矩阵时对角矩阵）。那么动能函数是（取T=1）：

$$K(p)=\sum\limits_{i=1}^{d}{\frac {p_i^2}{2m_i}}$$

HMC的步骤可以概括为以下两步：

1.改变动量：动量的新值从和q独立的高斯分布中采样得到，由于q的不变性，位置变量从条件分布$P(p|q)$中采样得到；

2.使用Metropolis 算法来更新通过Hamiltonian dynamics 找到的新的建议状态。从当前状态$(q,p)$开始，用步长ε，leapfrog方法模拟L步哈密顿系统。这里L和ε需要调整已得到好的采样表现,在L步之后，将动量P设为相反，得到新的状态(q∗, p∗).

$$ p(q^*,p^*)\propto e^{-[U(p^*)+K(p^*)]}$$
要保证哈密顿力学之后提出的新状态的概率大于哈密顿动力学之前状态的概率，即
$$p(q_0,p_0)\propto e^{-[U(q^{t-1})+K(p^{t-1})]}$$

所以这个状态的接受概率是：$$min[1,exp(-H(q^*,p^*))+H(q^{t-1},p^{t-1})]=min[1,exp(-U(q^*)+U(q^{t-1})-K(p^*)+K(p^{t-1})]$$

如果这个状态被拒绝，那么下一个状态和当前状态相同。将P设为相反，使得使Metropolis 建议分布对称，使上面的接受率有效。实践中，设置相反这一步并不需要，因为K(p) = K( -p), 而且当下一次迭代时，第一步中的动量将会重新采样。

如果我们把HMC看做从q and p的联合分布中采样, 那么Metropolis 更新这一步就是使用通过哈密顿动力学来寻找建议点，从而保证了（q,p）的概率密度值不变或几乎不变。

```{r}
HMC = function (U, grad_U, epsilon, L, current_q)#U返回q值的势能，grad_U返回给定q时，U的偏导数
#epsilon代表leapfrog算法的步长，L代表轨迹的步长，current_q代表当前的位置
{
  q = current_q
  p = matrix(rnorm(length(q),0,1), ncol = 1)  #从均值为0，标准差为1的正态分布中进行抽样
  current_p = p
  # 动量先更新半步
  p = p - epsilon * grad_U(q) / 2
  # 位置和动量的交替整部
  for (i in 1:L)
  {
    # 新的动量值把位置更新一步
    q = q + epsilon * p
    # 为动量迈出一整步，除了在轨迹的末端
    if (i!=L) p = p - epsilon * grad_U(q)
  }
  # 最后更新动量半步
  p = p - epsilon * grad_U(q) / 2
  #动量对称
  p = -p
  # 评估轨迹开始和结束时的势能和动能
  current_U = U(current_q)
  current_K = sum(current_p^2) / 2
  proposed_U = U(q)
  proposed_K = sum(p^2) / 2
  # 接受或拒绝轨迹结束时的状态
  # 轨迹末端的位置或初始位置
  if (runif(1) < exp(current_U - proposed_U + current_K - proposed_K))
  {
    return (q)  # 接受
  }
  else
  {
    return (current_q)  # 拒绝
  }
}

#二维正态分布中采样

mu = c(0, 0)
sigma = matrix(c(1, 0.95, 0.95, 1), nrow = 2)
inverse = solve(sigma)#求逆矩阵

#势能
U_P = function(q)
{
  inv_sigma = inverse
  value = t(q - mu) %*% inv_sigma %*% (q - mu)/2
  return(value)
}

#梯度
dU = function(q)
{
  inv_sigma = inverse
  K = inv_sigma %*% (q - mu)
  return(K)
}

#模拟
N = 20000
q_HMC = matrix(NA, nrow = 2, ncol = N)
q_init = matrix(c(-1.5, -1.55), ncol = 1)

for (i in 1:N) 
{
  
  q_HMC[,i] = HMC(U = U_P, grad_U = dU, epsilon = 0.25, 
                  L = 25, current_q = q_init)
  q_init = q_HMC[,i]
}

plot(q_HMC[1,], q_HMC[2,],  col= "red")

#动画图
library(animation)
saveGIF(
  {
    ani.options(interval = 0.1)
    for (i in 1:150) 
    {
      plot(q_HMC[1,1:i], q_HMC[2,1:i],
           xlim = c(-2, 2), ylim = c(-2, 2),
           type = "b", col= "red")
    }
  }
  ,movie.name = "hmc.gif")

```


Hamiltonian方法的缺点是，它需要连续的参数空间，对于离散的参数分布，它无法进行遍历。此外，Hamiltonian方法还需要进行调参，一个好的初始参数能够大大提高抽样效率。手动调参是一个很麻烦的过程，不过还好STAN软件可以进行自动调参。

##  8.9 初始HMC:map2stan

R语言的rethinking包可以通过map2stan来实现HMC。之前的文章中介绍过国家地形平整度和GDP关系的例子，当时是通过map函数的平方估计来实现的。

```{r}
library(rethinking)
```

```{r}
#载入数据
data("rugged")
d <- rugged#地势崎岖
d$log_gdp <- log(d$rgdppc_2000)#2000年人均GDP对数
dd <- d[complete.cases(d$rgdppc_2000),]#删除缺失数据之后的完整数据
```

```{r}
m8.1 <- map(
 alist(
 log_gdp <- dnorm(mu,sigma),
 mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa,
 a ~ dnorm(0,100),
 bR ~ dnorm(0,10),
 bA ~ dnorm(0,10),
 bAR ~ dnorm(0,10),
 sigma ~ dunif(0,10)
 ),
 data = dd
)

precis(m8.1)


```

下面是通过map2stan来实现HMC的过程。

### 8.9.1 数据准备

由于这里不再使用平方估计的方法，所以如果后验概率是非正态分布，那么我们抽样得到的也最终会是非正态分布。不过在做之前，要首先预处理一下数据。包括数据形式的变换和剔除数据框中不必要的变量（列）。虽然这不是必要的，但是为了防止一些难以预料的错误，我们最好还是把数据整理清洗干净。

以下是以地势崎岖度数据集为例的代码：

```{r}
dd.trim<-dd[,c("log_gdp","rugged","cont_africa")]#数据框中只包含我们需要的3个变量
str(dd.trim)#生成的是170*3的一个数据框
```
### 8.9.2 模型估计

```{r}
m8.1stan <- map2stan(
 alist(
 log_gdp ~ dnorm(mu, sigma),
 mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa,
 a ~ dnorm(0,100),
 bR ~ dnorm(0,10),
 bA ~ dnorm(0,10),
 bAR ~ dnorm(0,10),
 sigma ~ dcauchy(0,2)
 ),
 data = dd.trim
)


```
除了函数名从之前的map变成了map2stan，其他变化不大。不过注意sigma的先验分布类型从之前的均匀分布变成了cauchy分布，该分布和T分布很相似，只不过分布的尾部密度比较高。当然，这儿如果继续使用均匀分布也是可以的。

经过一系列的分析处理和等待，我们可通过下面的命令来查看模型结果：
```{r}
precis(m8.1stan)
```
和之前平方估计方法相比，结果相差不大。但是这儿多出了几样新东西。首先是这里的置信区间是最大后验概率密度区间（HPDI），而不是普通的百分区间（PI）。其次，结果还多出了两列n_eff和Rhat，这两列主要是MCMC模型诊断用的。其中Rhat应该是接近1的。

### 8.9.3 再次抽样

由于上面的模型比较简单，所以使用默认的1000次抽样就足够了。但是如果模型比较复杂，可能一次抽样并不足够，我们还需要多次抽样，建立多个马尔科夫链。这时，为了提高计算速度，我们使用多核并行抽样。

下面是对上述模型的重抽样，4核并行计算，建立4条马尔科夫链。

```{r}
m8.1stan_4chains <- map2stan(m8.1stan,chains = 4,cores = 4)
precis(m8.1stan_4chains)
```

### 8.9.4 可视化

通过对样本进项可视化，可以直观地感受到当真实的后验分布是高斯分布时，用这种方法得到的对应后验样本分布如何。通过extract.samples()函数对模型后验概率进行重抽样（默认1000次）。

```{r}
post <- extract.samples(m8.1stan)
str(post)
```


使用pairs函数一次性绘制所有的样本，函数会自动标注相应的变量名称和相关系数：
```{r}
pairs(post)
pairs(m8.1stan)
```

可视化图形给出了每一个参数的后验概率分布情况，并且给出了各个参数的相关性。就本例子而言，参数的后验概率十分接近于正态分布。

###  8.9.5 模型的使用

一旦你有了后验概率的一个样本，比如上面post对象，也就意味着你掌握了该模型，然后可以干很多事了，比如模拟预测、计算参数差异、计算DIC和WAIC等指标。

比如，通过show()函数可以直接得到模型的DIC和WAIC。

```{r}
show(m8.1stan)
```
### 8.9.6 链的核查

如果马尔可夫链使用正确，那么在一个长期的过程中，模型应该会收敛，即后验概率。否则模型就会出问题。

我们可以使用路径图来检验核查模型收敛情况。路径图即按抽样顺序做的图，通过路径图可以对每一个参数进行核查，如果没有发现问题，那么我们就可以放心的使用该链了。下面是我们上例模型中的路径图：

```{r}
plot(m8.1stan)
```
 
 其中灰色部分表示的前1000个样本，称之为“适应样本”。通过这些“适应样本”，马尔可夫链可以学习如何更有效的从后验概率分布中更有效的抽样，所以这些样本并不是用来最后预测的。白色区域代表用来进行推断的样本。

从上图地势崎岖模型对应的马尔可夫链的轨迹图中可以看出，该马尔可夫链表现良好，平稳且充分混合。

那么什么样的路径图是一个没有问题的路径图呢？我们一般查看两个方面：

1）稳定性 

2）混合性

稳定性是指路径存在于后验概率分布范围内，比如一直围绕在一个中心周围，或者你可以认为链的平均值从开始到最后一直都是稳定的。

混合性是指相邻样本之间没有很高的相关性。也就是路径应当弯弯折折。

满足以上两点的路径都是好的马尔可夫链，那么什么是不好的呢？

##  8.10 调试马尔可夫链

MCMC是通常是自动完成的，很多使用者或许并不知道其中发生了什么，其实也没有必要知道其中发生了什么。但是这并不意味着我们就可以放任模型不管了。

### 8.10.1 需要抽取多少样本

我们可以通过iter和warmup等参数来设置样本量，默认是2000个样本，其中一半样本用来“热身”，另一半用来推断。那么我们到底设置多少样本合适呢？

首先，我们要知道，真正的样本是“有效样本数量”，而不是你给的那个原始样本数。有效样本数是从后验概率分布中估计的独立样本数量，马尔可夫链通常是自相关的，所以序列样本并非完全独立。其中n_eff就是模型估计的有效样本数量，它通常会低于实际抽样样本数。

其次，所需样本数量大小还决定于你想要得到什么。如果你想要后验概率分布的均值，那么不需要太多的样本就可以达到你的目的。可能数百个样本就足够了。但是如果你关心整个后验概率分布的情况，那么你可以就需要很多样本了。具体多少样本没有统一的答案，一般认为在一个经典的回归分析中，你至少要有200个有效样本数量才能对后验概率做很好的估计。

“热身”warmup样本数量的设定也是一个需要考虑的问题。一个较小的“热身样本”数量就意味着你有更多地样本用来推测，但是这样可能会导致抽样效率的降低。在Stan软件中，总样本数的一半都可以身为“热身”样本。对于一些简单的模型，可能不需要那么多“热身”样本。所以具体还是根据实际情况来调整。

### 8.10.2 需要多少条马氏链

通常我们在估计模型的时候，会用到多个马尔可夫链，我们可以通过chains参数来设定链的数量，可以通过cores参数来设定并行处理的CPU数量，以此加快速度。那么我们到底应该设定多少条链合适呢？

首先，如果你是看模型是否能够运行，是否存在错误的地方，那么此时一条链就够了。如果你想看链是否达到了预期效果，那么就应该需要多个链了。如果上面两个都没问题，就可以开始进行模型拟合和推断了，此时一条链就足够了。当然，如果你偏要使用多个链，也是可以的。

具体来说，当第一次对一个模型使用一条链的时候，并不能够确定该链是否真的合适。此时应该使用多条链，然后分别查看链的路径图，看看它们是否都能够收敛到同一个分布中。如果一条链在一个分布中，另一条链在另一个分布中，此时模型就存在问题，需要重新思考模型的设置了。通常情况下，我们会使用3-4条链来检查各个链的收敛情况。一旦通过上面对多条链的检查，就可以放心的去使用一条链来拟合推断模型了。

比如，对一个模型我们需要1000个“热身”样本，9000个实际样本，那么我们是使用一条链（iter=10000, warmup=1000)还是使用3条链（iter=4000, warmup=1000)？其实对于推断来说，你用一条链和三条链都无所谓。但是它们实际运行效率可能不同，3条链的情况实际上有3000个“热身”样本，由于“热身”阶段是运行最慢的一个阶段，所以，如果使用3条链，可能导致运行效率比较低。当然，如果你能够把3条链进行多核并行处理，其运行速度会超过一条链的情况。

具体使用多少链还应该根据实际情况来决定。但是对于经典的回归模型，一般是“4条短链核查，1条长链推断”。

### 8.10.3 调试出错的马氏链（野链）

一个经常遇到的问题是后验概率分布是一个非常宽泛扁平的分布。这种情况的出现往往是由于使用的先验概率提供的信息太少，过于扁平。这就会导致一个野链，算法会错误的从一些极端参数值中大量抽样。

举一个例子，如果一个正态分布只有两个观测值，-1和1，这时就会出现野链。

```{r}
y <- c(-1,1)
m8.2 <- map2stan(
 alist(
 y ~ dnorm(mu, sigma),
 mu <- alpha
 ),
 data = list(y=y), start = list(alpha=0, sigma=1),
 chain = 2, iter = 4000, warmup = 1000
)
```

```{r}
precis(m8.2)
```
可以看到，估计的参数非常之大，显然这是不正确的。-1和1的均值应该在0附近，所以我们期待的alpha也应该是0. 此外，虽然我们设置了4000次抽样，而最后实际有效样本量却很小（n_eff），同时Rhat也不接近于1. 所以这个模型的链是有严重问题的。

再看一下这个链的路径图。

```{r}
plot(m8.2)
```
可以看到链时不时就会漂移到离均值很远的地方，非常不稳定。

导致这种情况的原因是先验概率过于扁平和观测样本太少。一个扁平的先验概率就意味着参数的每一个值都是有均等的可能性，所以对于alpha，可能有无数个值去进行抽样，这也导致了链非常不稳定，以及产生一些很极端的值，整条链遍布着随机漂移。另外，只有两个样本，数据所能提供的似然性太低，也是导致问题的一个重要原因。

那么该怎么改进呢？其实不难，虽然数据量还是那么多，但是我们可以通过改变先验概率来改进模型。即便是非常弱的先验概率，也能有效的避免在一个无限大的参数空间进行抽样。比如，我们给alpha提供一个Normal(1，10)的先验分布，给sigma提供一个HalfCauchy(0,1)的先验分布。

$$ y_i \sim Normal(\mu,\sigma)$$
$$ \mu=\alpha$$
$$ \alpha \sim Normal(1,10)$$
$$ \sigma \sim HalfCauchy(0,1)$$

```{r}
m8.3 <- map2stan(
 alist(
 y ~ dnorm(mu, sigma),
 mu <- alpha,
 alpha ~ dnorm(1,10),
 sigma ~ dcauchy(0,1)
 ),
 data = list(y=y), start = list(alpha=0, sigma=1),
 chain = 2, iter = 4000, warmup = 1000
)

```
```{r}
precis(m8.3)
```
```{r}
plot(m8.3)
```

这时，再看最后模型拟合的结果，正常多了！不再出现那么极端的结果了。

为什么会出现这种情况，通过下面两张图来看上述模型的先验概率（虚线）和后验概率分布（实线）。

[![qBpbnO.png](https://s1.ax1x.com/2022/03/27/qBpbnO.png)](https://imgtu.com/i/qBpbnO)

可以看出，不管是$\alpha$的先验正态分布，还是$\sigma$的先验Cauchy分布，都是非常弱的先验概率，所以即便整个模型只有两个观测数据（-1和1），模型依旧能够轻松克服先验概率带来的限制。比如我们提供的alpha的先验概率分布均值为1，而模型最终得到了正确的估计结果0。$\sigma$的先验分布在0处取得最大值，但是后验分布的均值约为1.4，观测的标准差约为1.4.但是正是这种很弱的先验概率却十分有效的避免了链的漂移。使得模型认为一个极端大的值不太可能发生。

### 8.10.4 不可估参数

比如有下面一个模型，数据是从Normal(0,1)的正态分布模型中100次随机抽样得到的。其中均值参数是两个参数加和（a1+a2),所以a1和a2是不可识别参数，只有它们的加和是可识别的，而且该加和预期值应该为0。

$$ y_i \sim Normal(\mu,\sigma)$$
$$ \mu = \alpha_1 + \alpha_2$$
$$ \sigma \sim HalfCauchy(0,1)$$

```{r}
y <- rnorm(100,0,1)
m8.4 <- map2stan(
 alist(
 y ~ dnorm(mu, sigma),
 mu <- a1 + a2,
 sigma ~ dcauchy(0,1)
 ),
 data = list(y=y), start = list(a1=0,a2=0,sigma=1),
 chains=2, iter = 4000, warmup = 1000
)

```
```{r}
precis(m8.4)
```
对这个模型进行拟合，根据n_eff和Rhat可以判断，模型非常不好。而且a1和a2是两个非常大的相反值，参数区间非常大。出现这种情况，主要就是a1和a2无法进行估计和识别，只有它俩的加和可以，这也就是它俩加和约等于0的原因。

通过下图，可以看到3个参数的路径图，其中a1和a2两个参数的路径既不稳定也没有很好的一致性。
```{r}
plot(m8.4)
```


而此时如果给两个不可识别的参数加上先验概率分布，会是怎样？

```{r}
y <- rnorm(100,0,1)
m8.5 <- map2stan(
 alist(
 y ~ dnorm(mu,sigma),
 mu <- a1 + a2,
 a1 ~ dnorm(0,10),
 a2 ~ dnorm(0,10),
 sigma ~ dcauchy(0,1)
 ),
 data = list(y=y), start = list(a1=0,a2=0, sigma=1),
 chains=2, iter = 4000, warmup = 1000
)

```
```{r}
precis(m8.5)
```

```{r}
plot(m8.5)
```

从参数估计结果看，已经非常好了，两个参数都变成可以识别的参数了。模型中参数的路径图也变成非常稳定，每个参数的两条链一致性也变得很好了。而改变这一切的原因就是我们添加的先验概率。一个很弱的先验概率拯救了整个模型！

可能有些人会认为上面不可识别的参数$\alpha_1$和$\alpha_2$太容易发现了，自己在建立模型的时候不会出现这种低级失误。但是，如果你建立的模型很复杂，有很多预测变量，特别是在交互作用存在的时候，很容易在模型中出现不可识别参数，而这时就很难发现问题了。所以模型中一定要使用先验概率。同时，使用先验概率也能够加运行速度，告诉马尔可夫链哪儿是合理的参数抽样范围，哪儿不是，从而避免了在一个无限大的空间内很盲目的抽样。

## 8.11 总结

本文以形象化的例子介绍了马尔可夫链蒙特卡洛（MCMC）的原理，也简单介绍了三种常用的方法：Metropolis， Gibbs抽样以及Hamiltonian算法。MCMC的转移过程只与邻近状态有关，有之前或之后的状态都不相关，也与初始状态无关。MCMC过程通过不断抽样，达到一个稳定的链，使得参数估计收敛，以此可以很有效的估计出模型参数的后验概率分布，而且该过程不要求具体的后验概率分布类型，不管什么样的后验概率分布都可以使用MCMC。另外，在MCMC过程中，加入适当（哪怕很微弱）的先验概率能够很好的提高运行效率和模型最终效果。





