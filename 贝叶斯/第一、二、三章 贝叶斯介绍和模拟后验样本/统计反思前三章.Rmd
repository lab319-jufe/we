---
title: "统计反思前三章"
author: "高全金"
date: "2021/11/15"
output: 
      html_document : 
        toc: yes
        toc_float: yes
        toc.depth: 6
        toc_depth: 6
fontsize: 15pt
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = " ",
	prompt = TRUE,
	results = "hold"
)
```

# 统计反思

1.本书在后面的章节中会介绍每个方法背后计算步骤的原因：

(1)如果不了解模型背后处理信息的原理，会无法解释模型的输出，如果需要更加深入地理解统计模型，这就要求我们用更繁琐的计算方法；

(2)概念理解上的困难，在于学者如何定义统计目标，解释统计结果。还需要了解一些统计认识论，理解统计模型和假设检验之间的关系以及感兴趣的内在机制。

2.本章主要介绍两个不可能证伪的理由

(1)假设检验并不是模型：许多模型都和同一个假设相关，同时也存在多个假设对应同一个模型的情况。

(2)测量方式也会产生影响：即使我们认为数据是可以证明某模型是错的，其他观测者也可能会对我们的方法和观测产生怀疑。

# 模型介绍

模型可以对假设进行检验--所有的统计检验都是模型--也可以进行测量、预测和争论。以下主要着重介绍3种模型，它们在社会科学和生物科学领域都有广泛的应用。

1)贝叶斯数据分析

2)分层模型

3)通过信息准则进行模型比较

## 贝叶斯数据分析

频率法要求所有概率的定义都需要和可计数的事件以及他们在大样本中出现的频率联系起来。这使得频率学的不确定性依赖于想象中的数据抽样的前提------如果多次重复测量，我们将会收集到一系列呈现某种模型的取值。意味着参数和模型不可能有概率分布，只有测量才有概率分布，这些测量的分布成为抽样分布。这些所谓的抽样只是假设，一般情况下甚至不太合理。

贝叶斯方法将"随机性"视为信息的特质，而非整个世界。但是真实世界没有什么是严格随机的，我们仅用随机性来描述由于信息缺失导致的不确定性，比如投掷硬币是"随机的"，但硬币不是随机的，有随机性是投掷的过程。贝叶斯一开始就用概率来描述所有类型的不确定性。并未涉及任何人的"信念"或主观意见。贝叶斯数据分析只是一种处理信息的逻辑过程，将其看作描述理性信念标准方法的惯例称为贝叶斯主义。

## 分层模型

1.分层模型(也称为随机效应、变化效应或混合效应模型)

任何特定的参数都可以认为代表某个缺失的模型，知道模型参数的原理就很容易将新的模型嵌入到旧的模型中，得出一个含有多层不确定性的模型，每层都为下一层提供信息------即分层模型。

2.使用分层模型的4个理由：

1)对建立在重复抽样观测上的估计进行调整。如果在同一个个体、地点或时间点上得到多个观测，这样单层模型就会误导我们。

2)对抽样失衡的估计进行调整。当某些个体、地点或者时间点对应的样本特别多时，单层模型也可能会有误导性。

3)研究方差。分层模型直接对方差进行建模。

4)避免平均。平均的结果会减小方差，导致结果过度自信。分层模型让我们保持没有进行平均的原始数据，同时可以用平均后的值进行预测。

3.分层模型的种类：

缺失值填补模型、测量误差、方差分析、一些时间序列模型、一些空间和网络回归模型以及种系遗传回归，这些都是分层思想的应用。

## 模型比较和信息法则

信息法则：比较不同模型结构的测量组。所有这些法则的目标都是让我们通过对未来预测的准确度来比较模型。

AIC(最有名的信息法则)和它的同类都被称为"信息'法则，因为它们通过信息理论建立测量模型。(第6章介绍信息理论)

AIC和它的同类主要是帮助研究人员解决模型比较中通常遇到的两个难题：

1)过度拟合(第六章)

2)能针对同一个数据集同时比较多个模型，不需要所谓的零假设模型。


# 第二章 小世界和大世界

当哥伦布在1942年向西行驶，寻找新大陆的时候，他坚信地球是圆的，他同时也相信地球的周长只有3万公里（这比实际长度少了1万公里），所以他估算船队能够带足够的食物去寻找新大陆。虽然他低估了地球的大小，幸运的是他一路上遇到了很多陆地或者岛屿，供他补给，并最终达到了美洲巴哈马群岛。

哥伦布的小世界和大世界就好比统计中的模型和现实。小世界就是统计模型自己定义的一个世界。在小世界中，所有的可能性都是预先设定的。在这个小世界中，确保模型逻辑性很重要，确保模型能够在一定的假设下顺利运行。Bayesian模型在这种小世界中具有先天优势，没有其他模型能够比Bayesian模型更能充分利用数据信息。

而大世界则是模型真实运行的环境。在大世界中，可能会遇到小世界中未曾遇到过的问题。一个模型不能代表一个完整的大世界，模型在大世界中会出现错误。一个小世界成立的逻辑，在大世界中也未必成立。

本章内容将介绍Bayesian模型。Bayesian模型是依据小世界的证据来建立的。如果Bayesian模型的假设和现实很接近，那么它也能很好的刻画大世界。本章主要是关注小世界，解释概率论的一些内容，比如一件事发生的可能性大小。然后随之而来的就是Bayesian推论，Bayesian模型的组成，从数据中学习模型，如何进行参数估计。

## 2.1 路径花园

Bayesian并不是很玄学的东西，Bayesian推断也只不过是计数和比较各种可能性而已。

为了推断到底会发生什么，我们必须把所有可能会发生的情况都考虑进去。但是随着某些事情的发生，Bayesian模型会告诉我们那些情况是不可能的，那些是更有可能发生。我们去掉不可能的，留下可能的，直到最后，留下来的就是最符合我们认知的一种情况。

现在举个很简单的例子：

### 2.1.1 计算可能性

假设你有一个袋子，里面有4个球，这些球的颜色有两种，要么是蓝色的，要么是白色的。我们只知道袋子里有四个球，但是我们不知道每个颜色的球有多少个？这种情况下，这4个球就有5种可能。

(1)[白白白白]；

(2)[蓝白白白]；

(3)[蓝蓝白白]；

(4)[蓝蓝蓝白]；

(5)[蓝蓝蓝蓝]

这5种情况叫做猜测，当然其中只有一种可能性是真实存在的。

我们的目的就是基于现有的证据来推测上述5种情况的可能性大小。现在我们有了一些证据：我们依次有放回的从袋子中抽取1个球，结果我们得到了"蓝"、"白"、"蓝"的结果。这结果就是我们现有的信息，即data。

下面我们来考虑各个猜测的情况，如果袋子中的4个球是1蓝3白。通过概率论我们很容易得到，总共4X4X4=64种可能性。

如果画成花园的岔路就像下面的图一样。

![](https://s4.ax1x.com/2022/02/10/HN0hrQ.png)


我们每次抽出一个球，就会排除一些路径，直到最后我们就剩下了3中可能的路径出现我们观测到的蓝-白-蓝的情况。

同样的道理，我们考虑第二种猜测的可能性，就袋子中有2蓝2白，这种情况下，抽出蓝-白-蓝共有2X2X2 = 8种可能路径。当我们把所有5种猜测都考虑完的时候，得到如下情况：

![](https://s4.ax1x.com/2022/02/10/HN0rVA.png)


这样我们就得到了在我们现有观测条件下，各种猜测的发生路径多少。

### 2.1.2 使用先验信息

先验信息是我们事先知道的一些信息。在上述例子中，我们是没有用到任何先验信息的，我们假设对袋子中的球是一无所知的。

假如我们现在又进行一次抽样，又得到了一个蓝球。这个时候再去推测袋子中各种球的可能性，你有两种做法，第一种是把上面4次抽样（前3次 + 最近1次）当做一个实验，我们计算袋子中各种可能的概率大小。或者，把前3次抽样的结果当做先验信息，在此基础上加上第4次抽样的数据，依次推断袋子中球颜色可能性大小。当然，最终的结果是两种方法得到的答案是一致的。

下面我们来详解第二种方法，看看是怎样利用先验信息的。
![](https://s4.ax1x.com/2022/02/10/HNBiRK.png)

最左边一栏是袋子中各种颜色球的可能性，第二栏是我们在对应可能性下，抽到蓝球的方式数量，第三栏是我们第一次试验的时候得到的结果（先验信息），那么最后一栏就是目前经过4轮抽样之后得到了袋子中球的可能性大小（发生方式多少）。最后一栏的结果就是中间两栏结果的乘积。

在这个例子中，先验信息和新数据是一样类型的，即都是在同一个袋子中抽样。当然，先验信息还可以是其他的。比如，我们在抽样前，袋子的生产厂家告诉我们，他们在生产袋子的时候，每生产一个"3蓝1白"的袋子，就会生产**两个**"2蓝2白"和**3个**"1蓝3白"的袋子，那么这个时候我们的先验信息就变了。如下

![](https://s4.ax1x.com/2022/02/10/HNBtds.png)

各种情况的先验信息变成了[0,3,2,1,0]。我们得到的最终结果也会根据各种先验信息的不同而不同。

### 2.1.3 从计数到概率

上面的例子都是计数各个可能性发生的方式多少，当然，在实际中，我们更多地是使用概率。比如，我们在抽到2蓝1白的情况下，袋子中的球是1蓝3白的概率可以表示为:

$$
\begin{aligned}
&观察到[蓝白蓝]的情况下[蓝白白白]成立的可能性\\
&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\propto\\
&在[蓝白白白]的假设下得到[蓝白蓝]的方式数目\\
&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\times\\
&~~~~~~~~~~~~~~~~~~~~~~[蓝白白白]的先验可能性\\
\end{aligned}
$$ 

将袋中蓝色大理石的比例定义为p，对于【蓝白白白】的情况，$p=\frac{1}{4}=0.25$，将观测定义为$D_{new}$=[蓝白蓝]，这样一来就有如下的数学表达式：

$$ 观测到D_{new}情况下p成立的可能性=在p的假设下得到D_{new}的方式数目\times p的先验概率$$

上面的表达式意味着对于任何的p值，我们认为其成立的可能性正比于在该p取值的情况下路径花园对应的路径的数目。

最后，我们将计算出的这些可能性标准化到[0,1]区间上得到相应的概率值，标准化后，所有假设的可能性取值相加为1。

$$ 观测到D_{new}情况下p成立的可能性=\frac{在p的假设下得到D_{new}的方式数目\times p的先验概率}{所有p对应的乘积之和}$$

我们用定义的p和'可能性'更新该表格如下所示：

![](https://s4.ax1x.com/2022/02/10/HN0FBj.png)

**注：比如 0.15 = (3 * 0.2) / (0 * 0.2 + 3 * 0.2 + 8 * 0.2 + 9 * 0.2 + 0 * 0.2 )，其中，0.2表示蓝色大理石的比例p为0.25时的先验概率，由于这里假设所有情况都是一样的，所以每种情况的先验概率都是0.2 **

以上所述每一步计算都存在对应的应用概率理论的定义：

(1)假定蓝色大理石的比例P通常称为参数值。

(2)每个p的取值对应的产生数据的方式数目通常称为似然值。

(3)关于p的先验可能性通常称为先验概率。

(4)在特定p取值情况下，根据样本观测更新后的可能性取值称为后验概率。

## 2.2 建立模型

假设你手中有一个地球，你想估计地球表现陆地和海洋的各占多少。你进行了下面的实验，将地球抛在空中，然后接到手中，记录地球最上面的那一点是陆地(L)还是海洋(W)。你把这个实验重复了9次，得到了如下结果：

$$W  ~~L ~~ W ~~ W ~  ~W  ~ ~L  ~~W  ~~L  ~~ W$$

这一系列结果就是我们的观测数据，为了建立Bayes模型，我们需要：数据背景 - 贝叶斯更新 - 评估。

### 2.2.1 数据背景

即我们是怎样完成一次试验的，怎么收集我们观测数据的。比如在我们上述例子中，

（1）地球有一个真实但不确定的海洋覆盖率p；

（2）每一次投掷试验都会产生一个海洋覆盖率p以及陆地覆盖率1-p；

（3）假设每次投掷都是独立的。

有这样一个数据来源，我们后面建立模型就会很方便。为了方便后面的理解，这儿提前提示一下，地球海洋覆盖率大概在0.7左右。

### 2.2.2 贝叶斯更新

我们的目的是根据现有的观测来推测地球表面海洋覆盖率。这个覆盖率和我们前面讲到的袋子中蓝白球的比例是一样的，在不同的观测情况下，得到的覆盖率是不一样的。Bayes模型开始于一系列的先验概率，然后根据我们实时观测结果来产生后验概率，后验概率又可以作为下一次实验的先验概率，以此进行，即贝叶斯更新。

下面我们来详解这个更新过程。首先是我们需要一个地球海洋覆盖率的先验概率，但是我们没有相关的信息，所以**假设针对不同的海洋覆盖率其先验概率**都是一样的。看下图将9次试验更新的一个过程。

![](https://s4.ax1x.com/2022/02/10/HNBgoR.png)

其中n表示试验次数，W表示试验结果为海洋，L表示实验结果为陆地，横坐标为地球海洋覆盖率，纵坐标为对应覆盖率存在的可能性。虚线为前一次得到的概率，相当于本次试验的先验概率，实线是加入本次观测结果后得到的后验概率。

比如第一次实验（最左上角的图），由于没有经验信息可用，所以对于各个海洋覆盖率的可能性都是一样的（先验概率相同），即虚线为水平直线，本次试验结果为W，即海洋，这个时候出现了实线（后验概率），**即海洋覆盖率为0的可能性变成了0（实线起点）**。

接着我们进行了第二次试验，依次类推。

可以看到，**每得到一次L的实验结果，实线就向左移动一次；每得到一个W的实验结果，实线就向右移动一次（即地球海洋覆盖率更高的可能性也大）**。最后我们得到了最右下角一张图。

这里假设海洋的比例只取0，0.25，0.5,0.75，1这5个数，与第一小节的对应，可以计算每一次投掷球的后验概率，将其作为下一次投掷球的先验概率，就可以算出贝叶斯更新后的结果，R代码展示如下：

首先定义初始未进行实验的一个数据：
```{r}
`可能出现的情况` <- c('0海洋4陆地','1海洋3陆地','2海洋2陆地','3海洋1陆地','4海洋0陆地')
`海洋的概率p` <- c(0, 0.25, 0.5, 0.75, 1)
`最初使用的先验概率` <- rep(0.2,5)
data <- data.frame(`可能出现的情况` , `海洋的概率p`, `最初使用的先验概率`)
dat <- c('w','l','w','w','w','l','w','l','w')
```

接着通过循环计算出每一次实验后的后验概率，并展示通过9次实验后得到的结果data：
```{r}
for(i in 1:length(dat)){
  if(dat[i] == 'w'){
      data[paste0('经过第', i, 
                  '次实验后的计数')] <- 0:4
    }
  else if(dat[i] == 'l'){
    data[paste0('经过第', i, 
                '次实验后的计数')] <- 4:0
  }
  prop <- round(data[,2* (i+1) -1] * data[,2 * (i+1)]/sum(data[,2* (i+1) -1] * data[,2 * (i+1)]),2)
  data[paste0('经过第', i,
              '次实验后的后验概率')] <- prop
}
data
```

然后通过R的绘图软件绘制出形如上图的一个结果：
```{r}
par(mfrow = c(3,3))
par(mar = c(1,1,1,1))
for(i in 1:length(dat)){
  plot(data[,2], data[,2 *i +1], type = 'b', lty = 2,
       xlab = NA, ylab = NA,
       xaxt = 'n', yaxt = 'n',)
  par(new = TRUE)
  plot(data[,2], data[,2 * (i + 1) +1], type = 'b', lty = 1,
       main = '第一次实验',
       ylab = 'possibility', xlab = NA,
       xaxt = 'n', yaxt = 'n',
       cex.main = 0.8, cex.lab = 0.8)
}
```

### 2.2.3 评估

如果模型中对大世界的描述是准确的，那么Bayes推断通常是最优的解决方案。但是对模型结果的评价和核查依旧是不可缺少的。如果模型和现实存在很大差异，那么模型的适用性就应当让人怀疑。即便是模型和现实符合的很好，也至少需要注意下面两个原则。

（1）模型的确定性并不能保证模型是一个好模型。比如上面的例子，随着地球投掷次数增大，曲线范围会变得越来越窄，那么地球海洋覆盖率变得确定性越来越高。但是，我们并不能保证这就是一个真实的情况，我们的推测都是建立在模型基础上的，我们不能保证选择的模型是一个好模型，换一个模型，可能得到不同的推论。比如，我们用的地球模型不能正确反映真实的海洋覆盖率，那么模型得到的确定性再高也没有意义。

（2）对模型进行检查评估是很重要的。在上面的例子中，9次试验的都是独立的，和试验顺序没有关系。所以不管你怎么投掷，只要是6次海洋3次陆地，最后的结果总是一样的。但是，如果试验之间不是独立的，那么就会得到完全不一致的结果。

## 2.3 模型组成

通过之前的内容，我们已经了解了这个机器的运行机理，现在就是开动机器，让它工作的时候了。回忆上一部分我们涉及到的几个概念：

1)每种假设下能够产生特定样本观测值的总路径数目。

2)每种假设下迭代产生所有样本观测的总路径数目。

3)每种假设成立的初始概率。

对应到模型中，就是

1）似然函数

2）一个或多个参数

3）先验

也就是一个模型的基本组成。

### 2.3.1 似然函数

Bayes模型的第一个，同时也是最重要的一个模型组成就是似然函数，它是描述观测数据在特定假设条件下发生的可能性大小的。比如上面例子的中的海洋覆盖率，从0-1，每一个值都对应一个当前观测发生的可能性大小。你可以根据自己的模型来构造自己的似然函数，也可以使用别人构造好的，经常用到的一些似然函数。不管是哪一种，你的似然函数应当能够告诉你当前观测发生的可能性。

在上面掷地球的例子中，我们假设了每次实验都是独立的，同时每次投掷得到W的概率都相等，也就是一个我们了解的典型的二项分布模型。在这种情况下，海洋覆盖率为p时，投掷n次地球，可以观测到w次海洋的概率为：

$$
Pr(w|n,p)=\frac{n!}{n!(n-w)!}p^w(1-p)^{n-w}
$$

在R语言中，可以通过dbinom函数来计算概率。

```{r}
dbinom(6, size = 9, prob = 0.5)
```

也就是在海洋概率为0.5的时候，投掷9次，出现6次海洋的可能性。

有时候似然函数也写为L(p\|w,n)。

### 2.3.2 参数

在上面的似然函数中有3个参数，即p，n和w。其中，实验次数n和观测次数w就是我们实际观测到的，只有参数p是未知的，Bayes模型的任务就是怎样通过观测数据来估计p的。

### 2.3.3 先验

在Bayes模型中，每一个需要估计的参数都要有一个先验概率。在上面的海洋覆盖率的例子中，**前一个实验的后验概率，成了下一次实验的先验概率**。不过在第一次实验的时候，我们没有任何先验概率，这个时候我们假设了概率分布是一条直线，即每种情况的先验概率都一样。

那么先验概率是从哪里得来的？它有时候是一个假设，比如上面提到的例子中所有的先验概率都一样。这也是我们在没有任何先验信息可用的情况下，常常使用的策略。这种先验概率通常被认为是弱信息先验概率，不过依旧很有用，很多非Bayes统计模型也使用了类似的策略。

更普遍的来讲，先验信息能够将参数限制在一个合理的范围内，体现出我们在没有任何观测数据之前对这一参数的认知程度。比如，在上面例子中，凭借我们的现有认知，地球表面海洋覆盖率不可能是0，也不会是1，同时覆盖率靠近0.5的值比靠近0和1的值更加靠谱。当我们没有很多先验信息的时候，这些常识对我们的判断仍然能够发挥较大的作用。

### 2.3.4 后验

对于每一组观测数据、似然函数、参数和先验概率的组合，Bayes模型都会给出一个唯一的估计值，这个估计值就是后验概率分布，即在现有观测的条件下，不同参数的可能性大小。后验概率分布表示为

$$Pr(p|n,w)$$

后验概率分布来是根据Bayes理论推导的。我们前面已经说过，在先验概率为p的情况下，发生w次的观测的可能性为：

$$Pr(w,p)=Pr(w|p)Pr(p)$$

也就是似然概率（或者叫做条件概率）Pr(w\|p)和先验概Pr(p)率的乘积。

举个例子，下雨和天冷发生在同一天的概率等于天冷时出现下雨的概率乘以天冷出现的概率。即

$$Pr(下雨，天冷)=Pr(下雨|天冷)∗Pr(天冷)$$

上面的表达式还有另一种形式，也是正确的：

$$Pr(w,p)=Pr(p|w)Pr(w)$$

同样是表达了下雨和天冷发生在同一天的概率等于下雨时出现天冷的概率乘以下雨出现的概率。

上面两个公式左边是一样的，只是右边不同。所以代换一下，就得到了下面的公式：

$$Pr(p|w)=\frac{Pr(w|p)Pr(p)}{Pr(w)}$$

上述这个公式就是Bayes定理。任何一个P发生的概率等于似然函数与先验概率的乘积，然后除以平均似然性。即

$$后验=\frac{似然函数 \times 先验}{平均似然}$$ 那么什么是平均似然性呢？就是针对每一个先验概率对应的似然性的平均值（其实也是一个先验概率）。它的目的主要是将数据标准化，使得所有后验概率的加和为1。

下面具体来看例子，前面我们在估算地球表面海洋覆盖率的时候，我们使用的先验概率是均一的，那么如果我们的先验概率不均一的，会对结果又和影响。下面几张图就说明了先验概率是如何影响后验概率的。

![](https://s4.ax1x.com/2022/02/10/HNBxl8.png)

横坐标表示海洋覆盖率，在似然函数分布一样的情况下（中间一列，根据我们的实验数据推测的），采用不同分布的先验概率（最左侧一列），得到的后验概率也是不一样的（最右侧一列）。

## 2.4 开始建模

我们通常需要用不同的数值方法来逼近贝叶斯定理给出的数学表达式。本书就要介绍以下三种方法：

1)网格逼近

2)二项逼近

3)马尔科夫链蒙特卡罗方法(第八章介绍)

### 2.4.1 网格逼近

1.定义

对于每个参数取值p',我们只需要计算后验概率，即将p'对应的先验概率乘以p'对应的似然函数值。在每个网格上取一个参数值计算相应的后验概率就能够大致逼近后验分布，这个过程就叫做网格逼近。

2.对模型进行网格逼近的步骤

1)定义网格。意味着需要用多个点来近似后验分布，然后将参数区域分成相应数目的网格选取参数值。

2)对每个参数值计算先验概率。

3)对每个参数值计算似然函数值。

4)将每个参数对应的先验概率乘以似然函数值得到没有标准化的后验概率。

5)最后通过除以所有后验概率取值的和对后验概率分布进行标准化。

以投掷球为例，用R代码实现以上5个步骤：

```{r}
#定义网格
p_grid<-seq(from=0,to=1,length.out=20) #生成从0-1之间间隔相同的20个数
head(p_grid)
```

定义先验分布$Pr(p)$

```{r}
prior<-rep(1,20)#将1重复20遍
```

计算网格每个参数取值对应的似然函数$Pr(w|p)$

```{r}
likelihood<-dbinom(6,size=9,prob=p_grid)#在每次给定概率取值的情况下，投掷9次，观测到6次水面的概率
head(likelihood)
```

计算似然函数和先验概率的乘积$Pr(w|p)Pr(p)$

```{r}
unstd.posterior<-likelihood*prior
head(unstd.posterior)
```

对后验概率进行标准化，标准化后概率之和为1 $$Pr(p|w)=\frac{Pr(w|p)Pr(p)}{Pr(w)}$$

```{r}
posterior<-unstd.posterior/sum(unstd.posterior)
head(posterior)
```

3.绘制得到的后验分布

mtext(as.character(i),side=j,line=i,outer=FALSE)\#mtext默认为outer=FALSE即在内边界注释文本，line表示与图像区域的距离(行高)

```{r}
plot(p_grid,posterior,type="b",xlab="水域覆盖面积",ylab="后验分布概率")
mtext("20个取值")
```

我们这儿只是使用了一个20个点的网格，你可以尝试使用不同大小的网格，网格越小，意味着你得到的结果越精确。

### 2.4.2 二项逼近（高斯逼近）

网格逼近有一个缺点，如果你的模型中有多个参数，那么你的计算量会成倍增长。比如有两个参数，每个都有100个网格，那么最终你要估计10000次。这个时候就体现出二项逼近的作用了。

一般情况下，后验概率的分布在分布的尖峰处会呈现出近正态分布。也就是说后验概率分布可以用正态分布来估计。我们知道正态分布很简单，只有两个参数就够了：位置参数（均值）和形状参数（方差）。正态分布类似抛物线，一个二次函数就可以描述，所以称之为平方估计。二项逼近准确度很高，同时对计算的要求又不像网格逼近或者MCMC那么高。

对模型进行二项逼近的步骤：

1)寻找后验众数。通常是通过最优算法寻找分布的"顶峰"。

2)找到后验分布的峰顶，估计峰顶的曲率。

```{r}
library(rethinking)
# 构建模型
globe.qa <- map(
  alist(w ~ dbinom(9,p), # 二项分布的似然率
  p ~ dunif(0,1)), # 均一分布的先验概率
  data = list(w=6) # 观测到6次海洋
)

# 显示二项逼近的结果
precis(globe.qa)
```

通过上面的平方估计，可以看到p=0.67，标准差为0.16，也就是后验概率分布的标准差，89%的分布区间为0.42-0.92。我们将得到的这个正态分布与实际的后验概率分布作比较如下：

![](https://s4.ax1x.com/2022/02/10/HNDAf0.png)

图中黑线是确切后验概率分布，蓝线是通过二项逼近得到的后验概率分布，随着实验次数(n)的增加，蓝线分布越来越接近实际后验概率分布。这也证明了二项逼近的准确性。

## 2.5 map函数详解

使用map函数，能够快速的找到二项逼近中的后验众数，其内部机制是通过拟牛顿法中的BFGS算法寻找到的MAP。

在介绍拟牛顿法之前，首先介绍梯度下降法和牛顿法：

### 2.5.1 梯度下降法

#### 2.5.1.1 梯度下降法介绍

$$
\begin{aligned}
F + \Delta F &= f(x+\delta)\approx f(x)+g^T\delta+\frac{1}{2}\delta^TH\delta\\
\Delta F &\approx g^T\delta
\end{aligned}
$$

其中，$\Delta F$表示梯度方向，g表示梯度。当$\Delta F$ 大于0时，表示是上升的方向，当$\Delta F$小于0时，表示的是下降的方向。

![](https://s4.ax1x.com/2022/02/10/HNaHPK.png)

现在寻找下降最快的方向，由于 $$
\Delta F \approx ||g^T|| *||\delta||*cos\theta
$$

于是，

（1）当$cos\theta$大于0，即当$\theta$在区间$(0,\frac{\pi}{2})$时，$\Delta F$大于0，此时$g^T$ 和$\delta$的方向夹角是个锐角；

（2）当$cos\theta$小于0，即当$\theta$在区间$(\frac{\pi}{2},\pi)$时，$\Delta F$小于0，此时$g^T$ 和$\delta$的方向夹角是个钝角。

于是，只有当夹角等于$\pi$时，下降速度就快，也就是说，我们需要寻找的方向就是负梯度方向。

#### 2.5.1.2 梯度下降法特征

（1）d = -g ；方向

（2）$\delta$ = $\alpha$ d ；找到最优的步长参数$\alpha$

（3）$d_{k+1}^T d_k = 0$，上一次迭代的方向与下一次垂直

（4）$x_{k+1}=x_k+\delta_k d_k$：迭代公式

![](https://s4.ax1x.com/2022/02/10/HNdcdI.png)


#### 2.5.1.3 梯度下降法的R语言实现

![](https://s4.ax1x.com/2022/02/10/HNwmOH.png)


以为例子$f(x)=(x-2.5)^2-1$

```{r}
Y <- function(theta){
  return((theta - 2.5)^2 - 1)
}#定义目标函数
dY <- function(theta){
  return(2*(theta - 2.5))
}#求目标函数的一阶导函数
```

```{r}
eta <- 0.1 #自定义步长
epsilon <- 1e-5#定义退出条件的最小epsilon
theta <- 0.0#定义初始点
theta_history <-  vector()#每一次迭代的取值点
i <-  1#记录迭代次数
i_max <- 100 #定义最大迭代次数
while(i < i_max){
  theta_history[i] <-  theta
  gradient <- dY(theta)
  last_theta <-  theta
  theta <-  theta - eta * gradient #梯度下降法的迭代公式
  i <- i+1
  
  if (abs(theta - last_theta) < epsilon){
    break
  }
}
i
theta
theta_history
```

将迭代结果可视化

```{r}
plot_x <- seq(-1, 6, 0.05)
plot_y <- (plot_x-2.5) ^ 2 - 1
plot(plot_x, Y(plot_x), lty = 1, type = 'l', col = 'blue', lwd = 3)
lines(theta_history, Y(theta_history), type = 'o', col = 'red', pch = 16, lty = 1, lwd = 2)
```

### 2.5.2 牛顿法（Newton）

上面的梯度下降法只用到了泰勒展开的一阶导数，缺点是收敛速度较慢，为了提高收敛速度，现将$f(x)$展开到二次，利用二次导数（海塞矩阵）来最优化函数值。下面来介绍牛顿法：

#### 2.5.2.1 牛顿法简介


$$\begin{aligned}
 f(x+\delta) &\approx f(x)+g(x)^T\delta+\frac{1}{2}\delta^TH(x)\delta\\
令~~~\frac{\partial f}{\partial \delta} &=0\\
得~~~~~~~\delta &= -H^{-1}g   ~~~这就是牛顿方向
\end{aligned}$$

所以,牛顿法的迭代公式为$x_{k+1}=x_k+(-H^{-1}g)$，与前面梯度下降法对比，牛顿法不仅利用了函数的一阶导数，而且还用上了二阶导数（海塞矩阵），

为了更加简单的感受牛顿法，这里用展示牛顿法在一元函数中如何使用：

将函数f(x)利用泰勒公式在点$x_k$附件展开到二阶：

$$f(x)=f(x_k)+f'(x_k)(x-x_k)+\frac{1}{2}f''(x_k)(x-x_k)^2$$
然后对上式两边对$x$的偏导并令导数为0：

$$0=f'(x_k)+f''(x_k)(x-x_k)$$
即可得到牛顿法的更新公式：

$$x=x_k-\frac{f'(x_k)}{f''(x_k)}$$

下面是他的一个收敛过程图解：

![](https://s4.ax1x.com/2022/02/10/HNDs9P.png)

#### 2.5.2.2 牛顿法特点

牛顿法中由$\Delta F= g^T\delta = -g^T H^{-1} g \leqslant 0$得，只有当$H \geqslant 0$（正定才行），而且这能通过上式中求海塞矩阵的逆也能得出海塞矩阵$H$必须正定才能计算，否则就达不到一个收敛的效果;

但是，如果海塞矩阵不正定怎么办呢，这时候可以通过加上一个比较大的值来实现

$$
\hat{H_k} = \frac{H_k+\beta I_n}{1+\beta}
$$ 由于$H_k$是一个对称阵，所以它一定可以化成一个对角阵，如果它不是正定的话，它们就有特征值是小于0的，这时候可以通过加上一个大于0的$\beta$乘以一个单位阵来解决这个问题。

$$\left[
 \begin{matrix}
   \lambda_1 &  0 &\dots& 0 \\
   0 & \lambda_2 & \dots & 0 \\
   . & . & . & .\\
    . & . & . & .\\
     . & . & . & .\\
   0 & 0 & \dots&\lambda_n
  \end{matrix}
  \right]$$

解释：$\lambda_1、\lambda_2,,,,\lambda_n$是从大到小排列的，如果$\lambda_n$是小于0的，则只需要加上一个比它相反数稍微大一点的$\beta$就可以解决$H$不正定的问题了。

特别地，如果$\beta$很大的话，$\hat{H_k} \approx I_n$，这时候就是上面提到的梯度下降法。

#### 2.5.2.3 牛顿法的步骤

（1）给定初始值$x_0$和精度阈值$\epsilon$，设置k=0;

（2）计算梯度$g_k$和矩阵$H_k$;

（3）如果$||g_k|| \lt \epsilon$即在此点处的梯度的值接近于0，则达到极值点，停止迭代;

（4）计算搜索方向$d_k = -H_k^{-1}g_k$;

（5）计算新的迭代点$x_{k+1}=X_k+\gamma d_k$;

（6）令k=k+1,返回步骤2；

#### 2.5.2.4 牛顿法与梯度下降法的比较

与梯度下降法相比，牛顿法的特点：

（1）迭代次数少、收敛速度快；

（2）得到的最小值点比较准确；

（3）没有选取步长的麻烦；（牛顿法的步长就是在那点的二阶导数值的倒数）

**缺点是需要计算目标函数的二阶梯度，也就是Hesse矩阵，可能计算量较大。**

#### 2.5.2.5 R语言实现

以为例子$f(x)=(x-2.5)^2-1$

```{r}
Y <- function(theta){
  return((theta - 2.5)^2 - 1)
}#定义目标函数
dY <- function(theta){
  return(2*(theta - 2.5))
}#求目标函数的一阶导函数
dY1 <- function(theta){
  return(2)
}
```

```{r}
epsilon <- 1e-5#定义退出条件的最小epsilon
theta <- 0.0#定义初始点
theta_history <-  vector()#每一次迭代的取值点
i = 1#记录迭代次数
i_max <- 100 #定义最大迭代次数
while(i < i_max){
  theta_history[i] = theta
  gradient = dY(theta)
  gradient1 = dY1(theta)
  last_theta = theta
  theta = theta - gradient/gradient1 #梯度下降法的迭代公式
  i <- i+1
  
  if (abs(theta - last_theta) < epsilon){
    break
  }
}
i
theta
theta_history
```

将迭代结果可视化

```{r}
plot_x <- seq(-1, 6, 0.05)
plot_y <- (plot_x-2.5) ^ 2 - 1
plot(plot_x, Y(plot_x), lty = 1, type = 'l', col = 'blue', lwd = 3)
lines(theta_history, Y(theta_history), type = 'o', col = 'red', pch = 16, lty = 1, lwd = 2)
```

### 2.5.3 拟牛顿法

上面的分析中提到，牛顿法的一个特点是在每一次要得到新的搜索方向的时候，都需要计算Hesse矩阵（二阶导数矩阵）。在自变量维数非常大的时候，这个计算工作是非常耗时的，因此，拟牛顿法的诞生就有意义了：它采用了一定的方法来构造与Hesse矩阵相似的正定矩阵，而这个构造方法计算量比牛顿法小。现在重新来考虑下面的多元泰勒展开：

$$
f(x) =f(x_{k+1})+g_{k+1}^T(x-x_{k+1})+\frac{1}{2}(x-x_{k+1})^TG_{k+1}(x-x_{k+1})
$$

其中，$g_{k+1}^T=\nabla f(x_{k+1})$，表示的是目标函数在$x=x_{k+1}$的梯度，是一个向量；

$G_{k+1} = \nabla^2f(x_{k+1})$，表示的是目标函数在$x=x_{k+1}$处的Hesse矩阵。

上式两边同时对$x$求导，即为

$$\nabla f(x)=\nabla f(x_{k+1})+G_{k+1}(x-x_{k+1})$$

在基本的牛顿法中，取得最值的点的导数值为0，即上式左侧为0，则

$$\nabla f(x_{k+1})+G_{k+1}(x-x_{k+1})=0$$

求出其中的

$$x=x_{k+1}-G_{k+1}^{-1} \nabla f(x_{k+1})$$

从上式中可知，在牛顿法中要求Hesse矩阵是可逆的

当$x=x_k$时，上式为 $$
\nabla f(x_k)= \nabla f(x_{k+1})+G_{k+1}(x_k-x_{k+1})
$$

此时，是否可以通过$x_k$、$x_{k+1}$、$\nabla f(x_k)$和$\nabla f(x_{k+1})$模拟出Hesse矩阵呢？

此方法便是**拟牛顿法**，上式便是拟牛顿方程，在拟牛顿方法中，主要包括DFP算法和BFGS算法。

#### 2.5.3.1 DFP算法

DFP算法也称DFP校正，是以Davidon、Fletcher、Powell三位牛人的名字的首字母命名的。

对于拟牛顿方程 

$$\nabla f(x_k)= \nabla f(x_{k+1})+G_{k+1}(x_k-x_{k+1})$$

可得 

$$G_{k+1}^{-1}[\nabla f(x_{k+1})-\nabla f(x_k)]=x_{k+1}-x_k$$

令$H_{k+1}=G_{k+1}^{-1}$,可得：

$$H_{k+1}[\nabla f(x_{k+1})-\nabla f(x_k)]=x_{k+1}-x_k$$

在DFP校正方法中，是用$H_{k+1}$来近似海塞矩阵的逆矩阵，假设

$$H_{k+1}=H_k+E_k \tag 1$$

在（1）式中，令

$$E_K=\alpha U_K U_k^T+\beta V_k V_k^T \tag 2$$

其中，$U_k$、$V_k$均为$n\times1$的向量；现在，我们的目标是求出 $\alpha、\beta 、U_k和V_k$。

这里令$g_k = \nabla f(x_{k+1})-\nabla f(x_k)$，$\Delta x = x_{k+1}-x_k$

则对于拟牛顿公式，可以化为

$$\begin{aligned}
H_{k+1}[\nabla f(x_{k+1})-\nabla f(x_k)]&=x_{k+1}-x_k\\ \\
H_{k+1}g_k &=\Delta x
\end{aligned}\tag3$$

（3）代入（1）得

$$(H_k+E_k)g_k=\Delta x\tag 4$$

（4）代入（2）得：

$$(H_k+\alpha U_K U_k^T+\beta V_k V_k^T)g_k=\Delta x\tag 5$$

通过（5）式可以得到：

$$(\alpha U_k^Tg_k)U_k+(\beta V_k^T g_k)V_k=\Delta x -H_k g_k \tag6$$

已知，$\alpha U_k^Tg_k$、$\beta V_k^T g_k$为实数，$\Delta x$ 和$H_k g_k$为$n \times 1$的向量。

上式中，参数$\alpha$和$\beta$解的可能性有很多，我们取特殊的情况，假设$\alpha U_k^Tg_k =1$，$\beta V_k^T g_k=-1$,那么$U_k=\Delta x$,$V_k=H_kg_k$

所以，我们得到$\alpha、\beta 、U_k和V_k$如下：

$$\begin{aligned}
U_k&=\Delta x=x_{k+1}-x_k\\ \\

V_k&=H_kg_k=H_k [\nabla f(x_{k+1})-\nabla f(x_k)]\\\\

由\alpha U_k^Tg_k =1得：\\\\
\alpha &=\frac{1}{U_k^Tg_k}\\\\
由\beta V_k^T g_k=-1得：\\\\\
\beta &= -\frac{1}{V_k^T g_k}
\end{aligned}$$

将上式代回（1）和（2）当中，可以得到：

$$\begin{aligned}
H_{k+1}&=H_k+E_k\\
&=H_k+\alpha U_k U_k^T+\beta V_kV_k^T\\
&=H_k+\frac{1}{U_k^Tg_k}\Delta x \Delta x^T - \frac{1}{V_k^Tg_k} H_k g_k g_k^T H_k\\
&=H_k+\frac{\Delta x \Delta x^T}{\Delta x^Tg_k} - \frac{H_k g_k g_k^T H_k}{g_k^T H_K g_k} \\
\end{aligned}$$

这个公式就实现了下一次迭代的海塞矩阵只需要用上一次的海塞矩阵逆矩阵求得即可，也就是说，计算海塞矩阵只需要计算第一次初始点对应的海塞矩阵的逆矩阵就行了。这就克服了每一次迭代过程中都要计算海塞矩阵逆矩阵的这一过程。

#### 2.5.3.2 BFGS算法

DFP算法是拟合海塞矩阵的逆矩阵，但BFGS算法是直接对海塞矩阵进行拟合，然后在对拟合后的矩阵求逆矩阵。

考虑DFG算法和BFGS算法的拟牛顿条件：

$$
\begin{aligned}
H_{k+1}g_k=\Delta x\\ \\
G_{k+1}\Delta x=g_k
\end{aligned}
$$

由**对偶定理**得


$$\begin{aligned}
H_{k+1}&\Leftrightarrow G_{k+1}\\
g_k&\Leftrightarrow\Delta x\\
\Delta x&\Leftrightarrow g_k
\end{aligned}$$

于是，BDGS算法中，下一次迭代的海塞矩阵为：

$$\begin{aligned}
G_{k+1}&=G_k+\frac{ g_k g_k^T}{g_k^T \Delta x} - \frac{G_k \Delta x \Delta x^T G_k}{\Delta x^T G_K \Delta x}\\
&=G_k+\frac{ g_k g_k^T}{g_k^T \Delta x} - \frac{G_k \Delta x (G_k \Delta x)^T}{\Delta x^T G_K \Delta x}
\end{aligned}$$

现在的一个新问题是，如何对求出$G_{k+1}$的逆矩阵，现在引入Sherman-Morrison Formula（谢尔曼-莫里森公式）

谢尔曼-莫里森公式：

如果A是非奇异（可逆）的，A的逆矩阵用$A^{-1}$表示，u和v是列向量，满足$1+v^T A^{-1}u \not =0$，那么，当$A+uv^T$非奇异时，其逆矩阵可以证明得到

$$(A+uv^T)^{-1}= A^{-1}-\frac{（A^{-1}u)(v^TA^{-1})}{1+v^TA^{-1}u}$$

证明过程如下：

![](https://s4.ax1x.com/2022/02/10/HNDT3V.png)

下面，只需要用两次谢尔曼-莫里森公式，就可以证明得到$G_{k+1}^{-1}$

以下给出推导公式：

我们已经得到了BFGS算法下的$H_{k+1}$的公式：

$$G_{k+1}=G_k+\frac{ g_k g_k^T}{g_k^T \Delta x} - \frac{G_k \Delta x (G_k \Delta x)^T}{\Delta x^T G_K \Delta x}$$

设$G_k=G_k^T$为$n \times n$的实对称矩阵，$g_k$，$\Delta x$为$n \times 1$的向量，我们希望得到$G_{k+1}^{-1}$

为方便叙述，这里省略下标k，首先令$H=G+\frac{gg^T}{g^T\Delta x}$，利用谢尔曼---莫里森公式，有

$$\begin{aligned}
G_{k+1}^{-1}&=(H-\frac{G \Delta x (G \Delta x)^T}{\Delta x^T G \Delta x})^{-1}
\\
&=H^{-1}-\frac{H^{-1}-\frac{1}{\Delta x^T G \Delta x}G \Delta x (G \Delta x)^TH^{-1}}{1+(-\frac{1}{\Delta x^T G \Delta x})  (G \Delta x)^TH^{-1}(G \Delta x)}
\\
&=H^{-1}+H^{-1}\frac{G \Delta x \Delta x^TG}{\Delta x^T G \Delta x-\Delta x^T G H^{-1} G \Delta x}H^{-1}
\end{aligned}$$

对于$H^{-1}$，再次利用谢尔曼-莫里森公式，有

$$\begin{aligned}
H^{-1}&=(G+\frac{gg^T}{g^T\Delta x})^{-1}
\\
&=G^{-1}-\frac{G^{-1}\frac{1}{g^T\Delta x}gg^TG^{-1}}{1+g^TG^{-1}g\frac{1}{g^T\Delta x}}\\
&=G^{-1}-G^{-1}\frac{gg^T}{g^T\Delta x+g^TG^{-1}g}G^{-1}\\
令Q=g^T\Delta x+g^TG^{-1}g\\
&=G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1}\\
\\
\end{aligned}$$ 

现在把$H^{-1}$代回上式中，首先计算第二项：

$$
\begin{aligned}
H^{-1}\frac{G \Delta x \Delta x^TG}{\Delta x^T G \Delta x-\Delta x^T G H^{-1} G \Delta x}H^{-1}\\&=(G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1})\frac{G \Delta x \Delta x^TG}{\Delta x^T G \Delta x-\Delta x^T G (G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1}) G \Delta x}(G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1})\\
&=(G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1})\frac{G \Delta x \Delta x^TG}{\Delta x^T G \Delta x-\Delta x^T G\Delta x+\frac{\Delta x^Tgg^T\Delta x}{Q} }(G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1})\\
&=\frac{Q}{\Delta x^Tgg^T\Delta x}(G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1})G \Delta x \Delta x^TG(G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1})\\
&=\frac{Q}{\Delta x^Tgg^T\Delta x}(\Delta x \Delta x^TG-\frac{G^{-1}gg^T\Delta x\Delta x^T G}{Q})(G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1})\\
&=\frac{Q}{\Delta x^Tgg^T\Delta x}(\Delta x \Delta x^T-\frac{\Delta x(\Delta x^Tg)g^TG^{-1}}{Q}-\frac{G^{-1}g(g^T\Delta x)\Delta x ^T}{Q}+\frac{G^{-1}g(g^T\Delta x\Delta x^Tg)g^TG^{-1}}{Q^2})\\
令k=\Delta x^Tg=g^T \Delta x\\
&=\frac{Q}{k^2}(\Delta x \Delta x^T-\frac{k \Delta x g^TG^{-1}}{Q}-\frac{k G^{-1}g\Delta x ^T}{Q}+\frac{G^{-1}k^2gg^TG^{-1}}{Q^2})\\
&=\frac{Q\Delta x \Delta x^T}{k^2}-\frac{ \Delta x g^TG^{-1}}{k}-\frac{ G^{-1}g\Delta x ^T}{k}+\frac{G^{-1}gg^TG^{-1}}{Q}\\
\end{aligned}
$$



现在把第一项加进去；

$$
\begin{aligned}
G_{k+1}^{-1}&=H^{-1}+\frac{Q\Delta x \Delta x^T}{k^2}-\frac{ \Delta x g^TG^{-1}}{k}-\frac{ G^{-1}g\Delta x ^T}{k}+\frac{G^{-1}gg^TG^{-1}}{Q}\\
&=G^{-1}-G^{-1}\frac{gg^T}{Q}G^{-1}+\frac{Q\Delta x \Delta x^T}{k^2}-\frac{ \Delta x g^TG^{-1}}{k}-\frac{ G^{-1}g\Delta x ^T}{k}+\frac{G^{-1}gg^TG^{-1}}{Q}\\
&=G^{-1}+\frac{Q\Delta x \Delta x^T}{k^2}-\frac{ \Delta x g^TG^{-1}}{k}-\frac{ G^{-1}g\Delta x ^T}{k}\\
&=(I-\frac{ \Delta x g^T}{k})G^{-1}-\frac{ G^{-1}g\Delta x ^T}{k}+\frac{(g^T\Delta x+g^TG^{-1}g)\Delta x\Delta x^T}{k^2}\\
&=(I-\frac{ \Delta x g^T}{k})G^{-1}-\frac{ G^{-1}g\Delta x ^T}{k}+\frac{\Delta x\Delta x^T}{k}+\frac{g^TG^{-1}g\Delta x\Delta x^T}{k^2}\\
\end{aligned}
$$

注意到$g^TG^{-1}g$是标量，故$g^TG^{-1}g\Delta x\Delta x^T=\Delta x (g^TG^{-1}g) \Delta x^T$所以继续对上述公式简化：

$$
\begin{aligned}
&=(I-\frac{ \Delta x g^T}{k})G^{-1}-\frac{ G^{-1}g\Delta x ^T}{k}+\frac{\Delta x\Delta x^T}{k}+\frac{\Delta xg^T}{k}\frac{G^{-1}g\Delta x^T}{k}\\
&=(I-\frac{ \Delta x g^T}{k})G^{-1}-(I-\frac{\Delta xg^T}{k})\frac{G^{-1}g\Delta x^T}{k}+\frac{\Delta x\Delta x^T}{k}\\
&=(I-\frac{\Delta x g^T}{k})G^{-1}(I-\frac{\Delta x g^T}{k})+\frac{\Delta x\Delta x^T}{k}
\end{aligned}
$$ 

于是，BFGS算法最终得到的结果为：

$$G_{k+1}^{-1}=(I-\frac{\Delta x g_k^T}{\Delta x^Tg_k})G_k^{-1}(I-\frac{\Delta x g_k^T}{\Delta x^Tg_k})+\frac{\Delta x\Delta x^T}{\Delta x^Tg_k}$$


#### 2.5.3.3 R语言实现牛顿法和BFGS算法

现在回到书本上的投掷球模型的例题，通过计算，我们可以得到最优化的目标函数如下：

$$
\begin{aligned}
f(x) &= C_9^6 ~x^6~(1-x)^3\\
取对数得:~~~~~~~~log(f(x))&=log(84) + 6*log(x)+3*log(1-x)
\end{aligned}
$$
所以我们的最优化目标函数就是上面式子。

##### 2.5.3.3.1 R语言实现牛顿法

```{r}
#定义函数
fun0a <- expression(3*log(1-x) + 6*log(x) + log(84))
fun1a <- D(fun0a,"x")
fun2a <- D(fun1a,'x')

fun0 <- function(x) eval(fun0a)
fun1 <- function(x) eval(fun1a)
fun2 <- function(x) eval(fun2a)
```


```{r}
#牛顿法
epsilon <- 1e-5#定义退出条件的最小epsilon
theta <- 0.01#定义初始点
theta_history <-  vector()#每一次迭代的取值点
i = 1#记录迭代次数
i_max <- 100 #定义最大迭代次数
while(i < i_max){
  theta_history[i] = theta
  gradient = fun1(theta)
  gradient1 = fun2(theta)
  last_theta = theta
  theta = theta - gradient/gradient1 #牛顿法的迭代公式
  i <- i+1
  
  if (abs(theta - last_theta) < epsilon){
    break
  }
}
i
theta
theta_history
```

可视化结果：

```{r}
plot_x <- seq(0, 1, 0.01)
plot_y <- fun0(plot_x)
plot(plot_x, fun0(plot_x), lty = 1, type = 'l', col = 'blue', lwd = 3)
lines(theta_history, fun0(theta_history), type = 'o', col = 'red', pch = 16, lty = 1, lwd = 2)

```

##### 2.5.3.3.2 R语言实现BFGS算法

```{r}
#定义函数
fun0a <- expression(3*log(1-x) + 6*log(x) + log(84))
fun1a <- D(fun0a,"x")
fun2a <- D(fun1a,'x')

fun0 <- function(x) eval(fun0a)
fun1 <- function(x) eval(fun1a)
fun2 <- function(x) eval(fun2a)
```

```{r}
#设置初始点
s1 <- 0.01
#第一次迭代
s1_div1 <- fun1(s1)
s1_div2 <- 1/fun2(s1)
s2 <- s1 - s1_div1 * s1_div2
epsilon <- 1e-5#定义退出条件的最小epsilon
i <- 1
prior <- s1
nex <- s2
theta_history <-  vector()#每一次迭代的取值点
i_max <- 100 #定义最大迭代次数
while (i < i_max) {
  theta_history[i] = prior
  d <- prior - nex
  g <- fun1(prior) - fun1(nex)
  dg <- d / g
  prior <- nex
  nex <- nex -fun1(nex) * dg
  i <- i + 1
  if (abs(d) < epsilon){
    break
  }
}
i
theta_history
nex
```
 
可视化结果

```{r}
plot_x <- seq(0, 1, 0.01)
plot_y <- fun0(plot_x)
plot(plot_x, fun0(plot_x), lty = 1, type = 'l', col = 'blue', lwd = 3)
lines(theta_history, fun0(theta_history), type = 'o', col = 'red', pch = 16, lty = 1, lwd = 2)
```

### 2.5.4 回顾二项逼近

现在我们再次回到二项逼近的一个过程

二项逼近包含两个步骤：

（1）寻找后验众数（MAP），像爬山一样接近后验分布的“顶端"。但是机器并不知道顶峰在哪，但是它能够计算脚下的坡度。（也就是在某一点的一阶导数值）

说明：在定义域内，若函数f(x)在x0处的一阶导数值小于0，要寻找到“峰值”，需要继续往小于x0的方向逼近；反之，若函数f(x)在x0处的一阶导数值大于0，需要继续往大于x0的方向逼近，直至找到一阶导数等于0的那个点，即为我们要找到的“峰值”，也就是MAP。

（2）估计峰顶的曲率。一旦找到了后验分布的“峰值”，就可以用在该点出的海塞矩阵（二阶导数值）来求得峰顶的曲率，也就是求得标准差。

说明：由于高斯分布的对数是一个抛物线方程，抛物线只有二阶导，因此，只要知道了抛物线的中心（第一个步骤中求得的MAP）和这个中心对应的二阶导数，我们就能确定该抛物线。实际上，高斯分布对观测的二阶导和其标准差的平方的倒数成正比.

推导公式如下：

$$
\begin{aligned}
f(x) &=\frac{1}{\sqrt{2\pi}\sigma}\exp \left[-\frac{(x-\mu)^2}{2\sigma^2} \right]\\
ln[f(x)]&=-\frac{1}{2}ln(2\pi)-ln(\sigma)-\frac{1}{2\sigma^2}(x-\mu)^2\\
\frac{\partial ln[f(x)]}{\partial x} &=-\frac{1}{\sigma^2}(x-\mu)\\
\frac{\partial^2 ln[f(x)]}{\partial x^2} &=-\frac{1}{\sigma^2}\\
\end{aligned}
$$

其实二阶导最后得到的标准差平方的倒数的值$-\frac{1}{\sigma^2}$，就是对应的后验分布在MAP处的二阶导数的值。

R代码可以容易求得：

```{r}
fun2(nex)
```

也就是说$-\frac{1}{\sigma^2}$ = `r fun2(nex)`，有错可以很容易的求得标准差（曲率）

```{r}
sqrt(abs(1/fun2(nex)))
```


## 2.6 总结

Bayes推断的目标是后验概率分布。后验概率描述了每种假设下产生观测数据的可能性，同时也是各种假设情况的可能性大小。

一个Bayes模型通常有三部分组成：似然性（条件概率）、参数和先验概率。似然性描述在一个特性参数值下，发生观测数据的可能性；先验概率是我们在纳入观测数据之前根据现有信息对每个参数值可能性的估计；通过上面的三个组成，然后使用一些估计方法（如网格逼近、二项逼近和MCMC），我们可以计算得到后验概率。

# 第三章 模拟后验样本

在本章中，我们通过第二章网格逼近得到的概率分布中**抽取样本**，随后对样本进行总结：

1)每种假设下能够产生特定样本观测值的总路径数目。

2)每种假设下迭代产生所有样本观测的总路径数目。

3)每种假设成立的初始概率。

最后，我们对模型进行检查，得到后验预测分布

## 3.1 后验分布的网格逼近抽样

现在回顾一下第二章中投掷球模型中如何通过网格逼近来计算后验分布

```{r message=FALSE, warning=FALSE}
library(rethinking)
```

```{r}
p_grid <- seq(from = 0,to = 1, length.out = 1000)
prior <- rep(1,1000)
likelihood <- dbinom(6,size = 9,prob = p_grid)
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
```

现在，我们想要从此后验分布中抽取10 000个样本。假设后验分布是一个装满各种参数取值 的口袋，比如0.1,0.5,0.7等。

在口袋中，每个取值存在的比率服从后验分布概率，也就是说，对应后验概率曲线峰值附件的取值出现比率比那些对应尾部的取值出现的比率高多了。

现在，我们开始从中抽取10 000个样本，我们假设该口袋里的取值充分混合，**得到的样本中各个取值的比例分布和后验概率的比例分布一致**，也就是说，**样本p取值的分布和后验分布成正比**。

下面是实现这一过程的R代码：

```{r}
#从p_grid中按照概率有放回的抽取10 000个样本
samples <- sample(p_grid , prob = posterior,size = 1e4 ,replace = TRUE)
samples[1:6]#展示sample的前6个值
```

现在将抽取的样本可视化

```{r}
plot(samples)
```

可以看到，在0.6附近的稠密区域有大量样本，在两端的区域样本稀释

```{r}
dens(samples)
```

上图展示了从样本得到的密度区间

```{r}
plot(p_grid ,posterior )
```

由上图可以看出，估计的密度区间和通过网格逼近得到的理想后验分布非常相似，如果增大样本数量，密度曲线会与理想情况更加接近。

```{r}
samples1 <- sample(p_grid ,prob = posterior ,
                   size = 1e5 , replace = TRUE)
dens(samples1)
```

上述仅仅是对后验概率进行了抽样，接下来我们需要通过这些样本对后验分布进行描述和进一步理解。

## 3.2 样本总结

一旦通过建模产生了一个后验分布，模型的任务就已经完成了。现在需要我们对后验分布进行总结和解释。

可以总结3类问题：

（1）某个取值区间对应的置信区间；

（2)某个置信度下的取值区间；

（3）某个取值点的密度估计。

### 3.2.1 取值区间对应的置信度

现在思考一个问题，水域覆盖率小于0.5对应的后验概率是多少？如果使用网格逼近，只需要简单地将那些参数取值小于0.5的点对应的后验概率相加。

```{r}
sum(posterior[p_grid < 0.5])
```

现在，让我们看看如何从后验分布中抽取的样本来进行相同的计算，实际上就是数数样本中有多少参数值小于0.5，然后除以样本量，即得到参数取值小于0.5的发生频率：

```{r}
sum(samples < 0.5)/1e4
```

```{r}
sum(samples1 < 0.5)/1e5
```

```{r}
samples2 <- sample(p_grid ,prob = posterior ,
                   size = 1e6 , replace = TRUE)
sum(samples2 < 0.5)/1e6

```

这里得到的结果和网格逼近的结果几乎一样，但完全不同，这是由于抽样的随机性导致的，所以每次运行得到的样本也不同。对应的区域如图3-2左图

![](https://s4.ax1x.com/2022/02/10/HNDx41.png)

可以用同样的方法得到取值在0.5到0.75之间的后验概率

```{r}
sum(samples > 0.5 & samples < 0.75)/1e4
```

所以取值在0.5和0.75之间的后验概率为61.5%，该区域上图3-2右图所示。

### 3.2.2 某个置信度下的取值区间

**置信区间**是在固定置信度下得到相应的取值区域

**置信度**是后验分布的区间概率（如上一节计算的）

这些后验返回的是区间的两个端点，参数取值在这两个端点之间的后验分布概率为指定的置信度。假如你想指知道左边80%置信度对应的置信区间，那该区间的左端点为0，现在找该区间的右端点，可以通过quantile()函数来找到其中80%的分位数：

```{r}
quantile(samples , probs = 0.8)
```

该区域如下图的左图所示

类似的，中间80%的置信区域在10%和90%分位数之间，能用类似的代码找到相应的端点：

```{r}
quantile(samples , probs = c(0.1, 0.9))
```

该区域如下图的右图所示。这种左右对称的区间我们将其称为**分位数区间**（Percentile Intervals , PI），只要不是过度不对称的分布，这些区间就能够很好的反映一个分布的形状，但如果密度函数是高度不对称的，**分位数区间并不完美**

![](https://s4.ax1x.com/2022/02/10/HNrHPI.png)

例如，在水域的例子中，假设投掷3次，连续观测到三次水域，并且使用均匀分布先验的情况，该分布高度倾斜，在p=1的时候得到最大值，现在用网格逼近来实现该过程：

```{r}
p_grid <- seq(from = 0,to = 1, length.out = 1000)
prior <- rep(1,1000)
likelihood <- dbinom(3,size = 3,prob = p_grid)
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
p_grid[which.max(posterior)]
```

接着从网格逼近中抽取后验样本，下图左边阴影部分是50%的置信区间，可以通过PI()函数（来自rethinking包）直接得到，这和quantile()函数得到的结果一样

```{r}
samples <- sample(p_grid,size = 1e4, replace = TRUE,prob = posterior)
PI(samples ,prob = 0.5)
quantile(samples , c(0.25,0.75))
```

![](https://s4.ax1x.com/2022/02/10/HNrlDg.png)

该区间涵盖了上25%和下25%分位数之间的区域，因此对应的置信度为50%，但是，该区间涵盖的参数取值大多在p =1附近，如果使用该区间来反映形状的话，拿将误导群众。

现在我们引入**最高后验密度区间**（HPDI），HPDI是相应置信度对应的最小区间，某个置信度对应的置信区间应该有无穷多个，但是，若想得到最能够反映数据分布情况的置信区间，那你希望得到取值分布最密集的区间，即**最高后验密度区间**，可以直接通过HPDI()函数得到该区间：

```{r}
HPDI(samples, prob = 0.5)
```

```{r}
PI(samples ,prob = 0.5)[[2]]-PI(samples ,prob = 0.5)[[1]]
HPDI(samples ,prob = 0.5)[[2]]-HPDI(samples ,prob = 0.5)[[1]]
```

可以看到该区间明显更窄，左边的分位数区间的密度是0.22，右边的分位数区间的密度是0.16。

![](https://s4.ax1x.com/2022/02/10/HNrU2V.png)

因此，最高后验概率区间比分位数区间更有优势，但在大部分情况下，这两种区间非常类似（因为大部分情况下是钟形分布），用两种方法得到的置信区间几乎没有差别，但是，对于高度倾斜的后验分布，这两个区间会看上去非常不同。

### 3.2.3 点估计

第3个也是最后一个常见的总结后验分布的方法是得到某种点估计

考虑掷球的例子，其中我们投掷了3次，3次观测都是水域，让我们考虑3个点估计（众数，均值和中位数）

首先，很容易得到最大后验估计（MAP）

```{r}
p_grid[which.max(posterior)]
```

或者可以使用来自后验分布的样本来逼近相同的统计量：

```{r}
chainmode(samples, adj = 0.01)
```

现在展示后验分布的均值或中位数呢

```{r}
mean(samples)
median(samples)
```

在这个例子中，众数（MAP）、均值和中位数是不同的，我们该如何选择呢？下图展示了该后验分布和对应的3个统计量估计

![](https://s4.ax1x.com/2022/02/10/HNsFzV.png)

如果不想使用整个后验分布估计，而是用另外一些统计量的话，标准途径是选择**损失函数**，损失函数是一个规则，该规则定义了使用特定点估计造成的损失。

现在用一个例子来帮助我们理解整个过程。假设下面一个赌局，告诉我你觉得地球上水域覆盖率p最可能是多少，如果你的答案完全正确，你会得到100美金，但如果你的答案和真实值有差距，将根据你的答案和真实值之间的差距，按比例从100美金中扣钱。也就是说，你的损失和d-p成正比，d是你的估计，P是真实的水域覆盖率，**损失和差距成正比**

一旦得到后验分布，该如何通过该分布**最大化效益期望**，也就是说，对任何决策方案计算相应的损失期望，意味着对每个参数取值的不确定性按照后验分分布进行平均，得到最小的损失期望。

因此，假设我们估计p=0.5，那么对应的损失期望为：

```{r}
sum(posterior * abs(0.5 - p_grid))
```

上述代码所做的就是计算加权平均损失，要对每一个值都进行加权平均，这里使用sapply()函数来实现：

```{r}
loss <- sapply(p_grid , function(d) sum(posterior* abs(d - p_grid)))
loss[1:6]
```

以上代码得到的loss中含有一系列的损失期望值，现在我们找到最小的损失期望值和其对于的估计值

```{r}
min(loss)
p_grid[which.min(loss)]
median(samples)
```

实际上，这就是后验中位数，由于抽样的随机性，这两个值可能不完全相同，但是很相近。

为了能够根据这个后验分布进行决策简化到用单个值进行决策，我们需要选择一个损失函数，不同的损失函数支持不同的估计，最常见的两个损失函数就是绝对离差（如上述例子）和离差平方损失$(d-p)^2$

**绝对离差对于的后验估计是后验中位数，离差平方损失对应后验均值**

## 3.3 抽样预测

后验分布样本的另外一个常见功能是为我们提供一个了解当前模型可能产生什么样本的简单方法，本章的最后一节将介绍如何模拟样本以及进行一些简单的模型评估。

### 3.3.1 虚拟数据

现在对这两个章节一直使用的投掷球模型进行总结。

首先，水域覆盖率P是存在且固定的，该值是我们想要估计的，将球投掷后得到观测，得到"水面"的概率是p，得到"陆地"的概率是 1-p

这些假设不仅让我们获得观测的情况下推断每个P取值的可能性，还让我们能够从后验分布中模拟模型可能产生的样本，这是因为给定观测，似然函数能够告诉你得到该观测的似然值，如果给定参数，似然函数定义了观测值的分布，可以根据该分布模拟可能的观测值。我们将这些模拟的数据称为**虚拟数据**，说明这不是真实的观测数据，而是一种近似或者模拟

在投掷球模型中，虚拟数据来自如下的二项似然函数：

$$ Pr(w|n, p) = \frac{n!}{w!(n-w)!}p^w(1-p)^{n-w}$$ 其中w是观测到水面的次数，n是总投掷次数。假设n=2，一共投了2次球，那么观测的水面的次数可能取值只有3个：0次，1次和2次。给定P的值，你能很容易计算出每个观测对应的似然函数。

假设P=0.7，该值大概是真是的地球表面海洋覆盖率：

```{r}
dbinom(0:2 , size = 2,prob = 0.7)
```

这意味着w=0的概率为9%，w=1的概率为42%，w=2的概率为49%。

现在，我们通过这些似然值来模拟观测，可以用rbinom()函数来实现，这里生成10个样本：

```{r}
dummy_w <- rbinom(10,size = 2,prob = 0.7)
table(dummy_w)/10
```

现在，生成100 000个虚拟数据，检查下每个观测出现的频率是否与相应的似然值成比例：

```{r}
dummy_w1 <- rbinom(1e5,size = 2,prob = 0.7)
table(dummy_w1)/1e5
```

这些取值和之前计算的理论似然值非常相近，由于抽样的随机性，他们可能并不完全相等。

只执行2次貌似不够，现在假设一共投掷了9次，同样模拟100 000个观测：

```{r}
dummy_w2 <- rbinom(1e5,size = 9,prob = 0.7)
simplehist(dummy_w2,xlab='dummy water count')
```

![](https://s4.ax1x.com/2022/02/10/HNsYee.png)

以上就是如何进行最基本的样本模拟

### 3.3.2 模型检查

模型不可能完美，因此我们要有自己的判断和取舍，现在，我们结合模拟观测（上一节讲到的）并通过后验分布模拟参数取值。

首先，观测具有不确定性。预测的样本具有不确定性，因为即使你确切的知道了P的取值，也不能知道下一次投球的结果（除非p=0或p=1)

其次，p的取值具有不确定性。这种不确定性体现了在后验分布中，由于P具有不确定性，于是一切与P有关的也具有不确定性。

于是，从模型中得到的预测包括了两种不确定性：**观测的不确定性和参数取值的不确定性**。

接着，我们将参数的取值的不确定性代入预测。这里要做的只是将不同取值的P对应的预测分布在P的后验分布上取平均。每个P对应一个观测的分布，计算出该样本分布后，你可以找到这个P取值对应的后验分布概率，然后用后验分布概率加权取平均，得到**后验预测分布**。

下图给出了这一加权的过程。

（1）图的上部是参数的后验分布，垂直标注的是10个不同的参数取值；

（2）每个参数取值对应的观测样本分布是中间那行条形图（也就是上一节中讲到的）；

（3）最后，在图的最底部，我们将所有p取值通过后验概率结合起来，计算得到没和可能观测的加权平均频率。

![](https://s4.ax1x.com/2022/02/10/HNsry8.png)
